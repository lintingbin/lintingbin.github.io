{"meta":{"title":"Darcy's Blog","subtitle":"不如烂笔头","description":"欢迎来到我的个人站","author":"lintingbin2009","url":"https://lintingbin2009.github.io"},"pages":[{"title":"categories","date":"2017-04-29T05:54:12.000Z","updated":"2017-04-29T07:32:37.249Z","comments":false,"path":"categories/index.html","permalink":"https://lintingbin2009.github.io/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2017-04-29T05:53:57.000Z","updated":"2017-04-29T07:36:27.413Z","comments":false,"path":"tags/index.html","permalink":"https://lintingbin2009.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"efficiency-guide:List处理","slug":"efficiency-guide-List处理","date":"2017-10-14T09:21:11.000Z","updated":"2017-10-14T10:29:42.123Z","comments":true,"path":"2017/10/14/efficiency-guide-List处理/","link":"","permalink":"https://lintingbin2009.github.io/2017/10/14/efficiency-guide-List处理/","excerpt":"","text":"列表创建不能使用如下代码创建列表，因为每次迭代都会创建一个新的列表:1234567bad_fib(N) -&gt; bad_fib(N, 0, 1, []).bad_fib(0, _Current, _Next, Fibs) -&gt; Fibs;bad_fib(N, Current, Next, Fibs) -&gt; bad_fib(N - 1, Next, Current + Next, Fibs ++ [Current]). 应该使用如下的代码创建列表:1234567tail_recursive_fib(N) -&gt; tail_recursive_fib(N, 0, 1, []).tail_recursive_fib(0, _Current, _Next, Fibs) -&gt; lists:reverse(Fibs);tail_recursive_fib(N, Current, Next, Fibs) -&gt; tail_recursive_fib(N - 1, Next, Current + Next, [Current|Fibs]). 列表推导列表推导现在仍然被认为是缓慢的。他们过去常常使用funs来实现，而funs过去很慢。以下的列表推荐：1[Expr(E) || E &lt;- List] 会被转换成本地的函数实现：123'lc^0'([E|Tail], Expr) -&gt; [Expr(E)|'lc^0'(Tail, Expr)];'lc^0'([], _Expr) -&gt; []. 如果列表推导的结果不会被使用，则不会构造列表。如下的代码：1234567891011[io:put_chars(E) || E &lt;- List],ok.%% 或者...case Var of ... -&gt; [io:put_chars(E) || E &lt;- List]; ... -&gt;end,some_function(...),... 上述的代码不会构造列表，所以转换成以下的本地函数实现：1234'lc^0'([E|Tail], Expr) -&gt; Expr(E), 'lc^0'(Tail, Expr);'lc^0'([], _Expr) -&gt; []. 编译器知道分配给’_’意味着该值不会被使用。因此，以下示例中的代码也将进行优化：12_ = [io:put_chars(E) || E &lt;- List],ok. 嵌套和拉伸列表(Deep and Flat Lists)lists:flatten/1比++操作更加的低效，在下述的情况中，可以很简单的避免使用lists:flatten/1: 向端口发送数据时。端口了解嵌套列表，所以没有理由在将列表发送到端口之前拉伸列表。 当调用接受嵌套列表的BIF时，例如list_to_binary/1或iolist_to_binary/1。 当知道列表只有一级嵌套时，可以使用list:append/1。 端口例子1234567...port_command(Port, DeepList) %% DO......port_command(Port, lists:flatten(DeepList)) %% DO NOT... 通常会这样向端口发送一个以0为结尾的字符串：1234...TerminatedStr = String ++ [0], % String=\"foo\" =&gt; [$f, $o, $o, 0]port_command(Port, TerminatedStr)... 上述效率比较低，应该用下述方式代替：1234...TerminatedStr = [String, 0], % String=\"foo\" =&gt; [[$f, $o, $o], 0]port_command(Port, TerminatedStr) ... Append例子123lists:append([[1], [2], [3]]). %% DOlists:flatten([[1], [2], [3]]). %% DO NOT 递归列表函数普通递归列表函数和尾部递归函数在结束的时候反转列表之间通常没有太大差异。因此，专注于编写好看的代码，并忘记了列表功能的性能。在代码的性能关键部分（仅在那里），用比较高效的写法就行了。 这部分是关于构造列表的列表函数。不构造列表的尾递归函数运行在常量空间中，而相应的普通递归函数使用与列表长度成比例的堆栈空间。 例如，一个将整数列表相加的函数不能写成如下：12recursive_sum([H|T]) -&gt; H+recursive_sum(T);recursive_sum([]) -&gt; 0. 应该写成:1234sum(L) -&gt; sum(L, 0).sum([H|T], Sum) -&gt; sum(T, Sum + H);sum([], Sum) -&gt; Sum.","categories":[{"name":"Erlang Efficiency Guide","slug":"Erlang-Efficiency-Guide","permalink":"https://lintingbin2009.github.io/categories/Erlang-Efficiency-Guide/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"efficiency-guide:Binary的构建和匹配","slug":"efficiency-guide-Binary的构建和匹配","date":"2017-10-14T05:11:44.000Z","updated":"2017-10-14T09:15:09.504Z","comments":true,"path":"2017/10/14/efficiency-guide-Binary的构建和匹配/","link":"","permalink":"https://lintingbin2009.github.io/2017/10/14/efficiency-guide-Binary的构建和匹配/","excerpt":"","text":"这篇文章非常详细的介绍了Binary是怎么样构造和匹配的，同时介绍了一些优化的技巧，没看过的一定要仔细看下。 以下代码可以高效的构建Binary(有点奇怪，和List不一样，下面构造Binary的段落会有解释):1234567my_list_to_binary(List) -&gt; my_list_to_binary(List, &lt;&lt;&gt;&gt;).my_list_to_binary([H|T], Acc) -&gt; my_list_to_binary(T, &lt;&lt;Acc/binary,H&gt;&gt;);my_list_to_binary([], Acc) -&gt; Acc. 以下代码可以高效的匹配Binary:123my_binary_to_list(&lt;&lt;H,T/binary&gt;&gt;) -&gt; [H|my_binary_to_list(T)];my_binary_to_list(&lt;&lt;&gt;&gt;) -&gt; []. Binary类型是怎么实现的?Binary和Bitstring在虚拟机的内部实现是一样的。在虚拟机的源代码中都叫做Binary。Binary类型在虚拟机内部由四种Binary对象实现: Refc BinariesRefc Binaries由两部分组成： 存储在进程堆上的对象，称为ProcBin Binary对象本身,它存储在所有进程堆之外 Binary对象可以由任意数量的进程引用任何数量的ProcBin。该对象包含一个引用计数器，用于跟踪引用数量，以便在最后一个引用消失时可以将其删除。进程中的所有ProcBin对象都是链表的一部分，因此当ProcBin消失时，垃圾回收器可以跟踪它们并减少二进制中的引用计数器。当构建的Binary大于64Byte的时候就会使用这种类型，此时进程之间发送Binary只是发送一个ProcBin。 Heap BinariesHeap binaries是小型Binary，最多64Byte，并直接存储在进程堆中。当Heap Binary被进程垃圾回收或者是作为消息发送时，都需要被复制。垃圾收集器不需要特殊处理。 Sub BinariesSub Binaries和match contexts对象能引用refc binary和heap binary对象的部分内容。Sub Binary是由split_binary/2创建的。一个Sub Binary引用另一个Binary的部分内容（只能引用Refc和Heap Binary，不能引用另一个Sub Binary）。因此，匹配一个Binary类型是比较高效的，因为实际的Binary数据是不会被复制的。 Match ContextMatch context和Sub binary比较类似，但是Match context专门为Binary匹配优化。（原文比较拗口，这里不做解释了，我也没太看懂） 构建BinaryBinary和Bitstring的append操作是被运行时系统特别优化的，只有在极少数的情况下优化是不起作用的。如下代码可以解释优化是如何起作用的:123456Bin0 = &lt;&lt;0&gt;&gt;,Bin1 = &lt;&lt;Bin0/binary,1,2,3&gt;&gt;,Bin2 = &lt;&lt;Bin1/binary,4,5,6&gt;&gt;,Bin3 = &lt;&lt;Bin2/binary,7,8,9&gt;&gt;,Bin4 = &lt;&lt;Bin1/binary,17&gt;&gt;,&#123;Bin4,Bin3&#125; 第1行分配一个Heap Binary给Bin0变量 第2行是append操作。由于Bin0没有涉及append操作，所以创建一个新的Refc Binary，并将Bin0的内容复制到其中。Refc Binary的ProcBin部分存有Binary对象的数据大小，而Binary对象还分配了额外的空间。Binary对象的大小是Bin1或256的大小的两倍，以较大者为准。在这个例子中是256。 第3行更有意思。Bin1已被用于append操作，最后有252字节的未使用内存，因此3个新的字节会被存储在这些空闲的内存中。 第4行。和第3行一样。剩下249个字节，所以存储另外3个新字节没有问题。 第5行。有趣的事情发生。请注意，Bin4是用Bin1来append值17。Bin4将被赋值为&lt;&gt;。Bin3将保留其价值&lt;&gt;。显然，运行时系统不能将字节17写入上述的Refc Binary中，因为这会将Bin3的值更改为&lt;&gt;。运行时系统知道Bin1是先前append操作的结果，所以它将Bin1的内容复制到一个新的Binary，预留额外的存储空间等等类似上面的操作。（这里没有解释为什么运行时系统知道不能写入到Bin1中，如果有兴趣的话可以阅读erl_bits.c源代码） 强制拷贝的情况Binary的append操作优化要求对于Binary:只有一个ProcBin指向一个Refc Binary的Binary对象。原因是优化需要在append操作期间移动（重新分配）Binary对象，并且同时更新ProcBin中的指针。如果有多个ProcBin指向Binary对象，则无法找到并更新它们。因此，对Binary的某些操作会被做标记，以便在将来做append操作的时候知道是否要强制拷贝Binary。在大多数情况下，Binary额外分配的空间也会在这个时候也被回收掉。如果将Binary作为消息发送到其他进程或端口，则binary对象会缩小，任何进一步的append操作都会将Binary数据复制到新的Binary中。例如，在下面的代码，第3行的Bin1将会被复制：123Bin1 = &lt;&lt;Bin0,...&gt;&gt;,PortOrPid ! Bin1,Bin = &lt;&lt;Bin1,...&gt;&gt; %% Bin1 will be COPIED 同样的情况一样会发生，如果将Binary插入到Ets表中、使用erlangport_command/2将其发送到端口、或者将其传递给NIF中的enif_inspect_binary。匹配Binary也会导致其缩小，下一个append操作将会复制Binary数据：123Bin1 = &lt;&lt;Bin0,...&gt;&gt;,&lt;&lt;X,Y,Z,T/binary&gt;&gt; = Bin1,Bin = &lt;&lt;Bin1,...&gt;&gt; %% Bin1 will be COPIED 原因是match context包含直接指向二进制数据的指针。如果一个进程简单地保留Binary（在“循环数据”或进程字典中），垃圾回收器最终可以收缩这个Binary。如果只保留一个这样的Binary，则不会收缩。如果该进程后续append到已收缩的Binary中，则Binary对象将被重新分配，以使数据被加上。 匹配Binary重新看下文章开头的匹配例子：123my_binary_to_list(&lt;&lt;H,T/binary&gt;&gt;) -&gt; [H|my_binary_to_list(T)];my_binary_to_list(&lt;&lt;&gt;&gt;) -&gt; []. 第一次调用my_binary_to_list/1时，会创建match context。match context指向Binary的第一个字节。匹配1个字节，并更新match context以指向Binary的第二个字节。在此时，创建一个sub binary似乎是有意义的，但是在这个特定的例子中编译器知道每次匹配后会马上调用一个函数（在这个例子中，是my_binary_to_list/1本身），这会导致要创建一个新的match context然后丢弃sub binary。因此，my_binary_to_list/1使用match context而不是使用sub binary调用自身。初始化匹配操作的指令当它看到它被传递给match context而不是sub binary时基本上什么都不做。当到达Binary的末尾并且第二个子句匹配时，match context将被简单地丢弃（在下一个垃圾回收中被移除，因为不再有任何引用）。总而言之，my_binary_to_list/1只需要创建一个match context，而不需要sub binary。注意，当遍历完整个Binary后，my_binary_to_list/1中的match context被丢弃。如果迭代在Binary结束之前停止，会发生什么？优化还会生效吗？123456after_zero(&lt;&lt;0,T/binary&gt;&gt;) -&gt; T;after_zero(&lt;&lt;_,T/binary&gt;&gt;) -&gt; after_zero(T);after_zero(&lt;&lt;&gt;&gt;) -&gt; &lt;&lt;&gt;&gt;. 答案是依然生效，编译器将在第二个子句中删除sub binary的构建：1234...after_zero(&lt;&lt;_,T/binary&gt;&gt;) -&gt; after_zero(T);... 但是它会生成在第一个子句中构建sub binary的代码：123after_zero(&lt;&lt;0,T/binary&gt;&gt;) -&gt; T;... 因此，after_zero/1将构建一个match context和一个sub binary（如果它传进一个包含0的binary）。以下代码也将进行优化：123456all_but_zeroes_to_list(Buffer, Acc, 0) -&gt; &#123;lists:reverse(Acc),Buffer&#125;;all_but_zeroes_to_list(&lt;&lt;0,T/binary&gt;&gt;, Acc, Remaining) -&gt; all_but_zeroes_to_list(T, Acc, Remaining-1);all_but_zeroes_to_list(&lt;&lt;Byte,T/binary&gt;&gt;, Acc, Remaining) -&gt; all_but_zeroes_to_list(T, [Byte|Acc], Remaining-1). 编译器将删除第二和第三个子句中的sub binary的构建，并向第一个子句添加一个指令，该指令将Buffer从match context转换成sub binary（如果Buffer已经是binary，则不执行任何操作）。在开始认为编译器可以优化任何Binary模式匹配之前，以下函数不能由编译器进行优化（至少当前是这样的）：123456non_opt_eq([H|T1], &lt;&lt;H,T2/binary&gt;&gt;) -&gt; non_opt_eq(T1, T2);non_opt_eq([_|_], &lt;&lt;_,_/binary&gt;&gt;) -&gt; false;non_opt_eq([], &lt;&lt;&gt;&gt;) -&gt; true. 之前提到，如果编译器知道Binary不会被共享，则会延迟创建sub binary。在当前的这种情况下，编译器无法知道。很快，下面的章节将解释如何重写non_opt_eq/2，以便可以应用延迟sub binary的优化，更重要的是，还能发现你的代码是否可以优化。 bin_opt_info选项使用bin_opt_info选项可以让编译器打印大量有关二进制优化的信息。 erlc +bin_opt_info Mod.erl 请注意，bin_opt_info不能是能永久添加到Makefile中的选项，因为它生成的所有信息都不能被删除。因此，通过环境选择在大多数情况下是最实际的方法。为了更准确地说明警告所引用的代码，以下示例中的警告将作为注释引用到它们所引用的子句之后插入，例如：12345678after_zero(&lt;&lt;0,T/binary&gt;&gt;) -&gt; %% NOT OPTIMIZED: sub binary is used or returned T;after_zero(&lt;&lt;_,T/binary&gt;&gt;) -&gt; %% OPTIMIZED: creation of sub binary delayed after_zero(T);after_zero(&lt;&lt;&gt;&gt;) -&gt; &lt;&lt;&gt;&gt;. 上述代码说明第一个匹配没有优化，第二个匹配会被优化。让我们重新回顾一下无法优化的代码的例子，并找出原因：123456789101112non_opt_eq([H|T1], &lt;&lt;H,T2/binary&gt;&gt;) -&gt; %% INFO: matching anything else but a plain variable to %% the left of binary pattern will prevent delayed %% sub binary optimization; %% SUGGEST changing argument order %% NOT OPTIMIZED: called function non_opt_eq/2 does not %% begin with a suitable binary matching instruction non_opt_eq(T1, T2);non_opt_eq([_|_], &lt;&lt;_,_/binary&gt;&gt;) -&gt; false;non_opt_eq([], &lt;&lt;&gt;&gt;) -&gt; true. 编译器发出两个警告。INFO警告指的是函数non_opt_eq/2作为被调用者，表示任何调用non_opt_eq/2的函数都不能进行延迟sub binary优化。还有一个建议来改变参数顺序。第二个警告（恰好是指同一行）是指sub binary本身的构造。下面的另一个例子将显示INFO和NOT OPTIMIZED警告之间的区别，这些警告有些清晰，但是让我们先来试一下改变参数顺序的建议：1234567opt_eq(&lt;&lt;H,T1/binary&gt;&gt;, [H|T2]) -&gt; %% OPTIMIZED: creation of sub binary delayed opt_eq(T1, T2);opt_eq(&lt;&lt;_,_/binary&gt;&gt;, [_|_]) -&gt; false;opt_eq(&lt;&lt;&gt;&gt;, []) -&gt; true. 编译器给出以下代码片段的警告：1234567match_body([0|_], &lt;&lt;H,_/binary&gt;&gt;) -&gt; %% INFO: matching anything else but a plain variable to %% the left of binary pattern will prevent delayed %% sub binary optimization; %% SUGGEST changing argument order done;... 这个警告意味着如果有一个对match_body/2的调用（来自match_body/2中的另一个子句或另一个函数），那么延迟的子二进制优化是不可能的。在二进制匹配结束处的任何地方将发生更多警告，并作为match_body/2的第二个参数传递，例如：1234match_head(List, &lt;&lt;_:10,Data/binary&gt;&gt;) -&gt; %% NOT OPTIMIZED: called function match_body/2 does not %% begin with a suitable binary matching instruction match_body(List, Data). 未使用的变量编译器能够算出一个变量是否未被使用。然后为以下每个功能生成相同的代码：12345678count1(&lt;&lt;_,T/binary&gt;&gt;, Count) -&gt; count1(T, Count+1);count1(&lt;&lt;&gt;&gt;, Count) -&gt; Count.count2(&lt;&lt;H,T/binary&gt;&gt;, Count) -&gt; count2(T, Count+1);count2(&lt;&lt;&gt;&gt;, Count) -&gt; Count.count3(&lt;&lt;_H,T/binary&gt;&gt;, Count) -&gt; count3(T, Count+1);count3(&lt;&lt;&gt;&gt;, Count) -&gt; Count. 在每次迭代中，二进制中的前8位将被跳过，不匹配。 历史笔记R12的Binary处理显着改善。因此R11B中执行高效的代码在R12B中可能不是那么高效，反之亦然，此efficiency-guide的较早版本包含了有关R11B中二进制处理的一些信息。","categories":[{"name":"Erlang Efficiency Guide","slug":"Erlang-Efficiency-Guide","permalink":"https://lintingbin2009.github.io/categories/Erlang-Efficiency-Guide/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"efficiency_guide:需要注意的模块和BIF","slug":"efficiency-guide-需要注意的模块和BIF","date":"2017-10-14T04:38:02.000Z","updated":"2017-10-14T04:42:07.425Z","comments":true,"path":"2017/10/14/efficiency-guide-需要注意的模块和BIF/","link":"","permalink":"https://lintingbin2009.github.io/2017/10/14/efficiency-guide-需要注意的模块和BIF/","excerpt":"","text":"以下就是要注意的模块和BIF，这些内容之前大多数知道，就setelement/3和size/1的使用优化是不知道的，值得一读 Timer模块使用erlang:send_after/3和erlang:start_timer/3创建定时器比使用Timer模块更有效率。Timer模块使用单独的进程来管理定时器。如果许多进程在同时创建和取消定时器，这个进程很容易成为瓶颈。此外Timer模块的有些函数是不通过单一的进程实现的（如定时器：tc/3或定时器：sleep/1），因此这些函数是可以放心使用的。 list_to_atom/1Atom是不进行内存回收的，一旦一个Atom被创建，它永远不会被移除。如果Atom的数量到达虚拟机的上限（默认1,048,576）的话，虚拟机将会奔溃。因此，在一个连续运行的系统中，将任意输入字符串转换成Atom是危险的。如果只允许某些定义好的原子作为输入，使用list_to_existing_atom/1可以用来防范拒绝服务攻击。使用list_to_atom/1构建一个可以被传入apply/3函数的atom，效率是比较低的，不推荐在需要运行很快的代码中使用:1apply(list_to_atom(“some_prefix”+ + Var), foo, Args) length/1与tuple_size/1、byte_size/1和bit_size/1的O(1)时间复杂度不同，length/1执行的时间与List的长度成正比为O(n)。通常，没有必要担心length/1的速度，因为它是用C语言很高效的实现的，但是如果List很长，为了避免O(n)的时间复杂度。在一些使用场景中length/1可以被模式匹配来代替,如下：12foo(L) when length(L) &gt;= 3 -&gt; ... 可以被写成模式匹配的方式12foo([_,_,_|_]=L) -&gt; ... 上面两段代码的区别是：如果L不是的列表，length(L)将会出错，而第二段代码中将不能正确匹配。 setelement/3setelement/3会复制其修改的tuple。因此，使用setelement/3循环更新一个tuple的不同字段，会每次创建一个tuple的新副本。有一种情况是可以例外的，如果编译器清楚地知道，破坏性地更新tuple会产生tuple复制相同的结果，那么对setelement/3的调用将被替换为一个特殊的破坏性设置指令。在以下代码中，第一个setelement/3调用复制该tuple并修改第9个元素：1234multiple_setelement(T0) -&gt; T1 = setelement(9, T0, bar), T2 = setelement(7, T1, foobar), setelement(5, T2, new_value). 后面两个setelement/3调用将该复制的tuple的d第7和第5个元素也修改了，不再复制新的tuple。要实现上述的优化，必须满足以下条件： 索引必须是整数文字，而不是变量或表达式。 索引必须按降序给出。 在连续的setelement/3调用之间不能有任何其他函数调用。 从一个setelement/3调用返回的元组只能在随后的setelement/3调用中使用。 如果代码不能像multi_setelement/1示例中那样被构造，那么修改大元组中的多个元素的最好方法是将元组转换为列表，修改列表，并将其转换回元组。 size/1size/1可以用来返回tuple和binary的大小。但是如果使用tuple_size/1和byte_size/1的话，能为编译器和运行时系统提供了更多优化机会。另一个优点是能给了Dialyzer提供更多的类型信息。 split_binary/2使用模式匹配而不是调用split_binary/2函数来分割二进制通常更有效率。此外，混合使用比特语法匹配和split_binary/2会使比特语法匹配的一些优化失效。12&lt;&lt;Bin1:Num/binary,Bin2/binary&gt;&gt; = Bin %% 推荐&#123;Bin1,Bin2&#125; = split_binary(Bin, Num) %% 不推荐 运算符 “- -““- -“ 运算符具有与其操作数长度乘积成比例的时间复杂度（O(m*n)）。这意味着如果该操作符的两个操作数都是长列表，那么操作者非常慢：12345678HugeList1 -- HugeList2%% 上述操作应该被替换成下面的操作HugeSet1 = ordsets:from_list(HugeList1),HugeSet2 = ordsets:from_list(HugeList2),ordsets:subtract(HugeSet1, HugeSet2)%% 如果在意列表的原始顺序的话，可以退换成如下的操作Set = gb_sets:from_list(HugeList2),[E || E &lt;- HugeList1, not gb_sets:is_element(E, Set)] 注意：如果列表包含重复的元素(HugeList2中出现一个元素在HugeList1中删除了所有出现的元素)，则该代码的行为与“- -”不同。另外，这个代码比较了使用“==”运算符的列表元素，而“- -”使用“=:=”运算符。如果这个区别很重要，那么可以使用set代替gb_set，但是在长列表中set:from_list/1比gb_sets:from_list/1慢得多。使用“- -”运算符从列表中删除一个元素不会有性能问题：HugeList1 – [Element] 。","categories":[{"name":"Erlang Efficiency Guide","slug":"Erlang-Efficiency-Guide","permalink":"https://lintingbin2009.github.io/categories/Erlang-Efficiency-Guide/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"efficiency_guide:七个Erlang性能的误区","slug":"efficiency-guide-七个Erlang性能的误区","date":"2017-10-14T04:35:14.000Z","updated":"2017-10-14T04:44:15.421Z","comments":true,"path":"2017/10/14/efficiency-guide-七个Erlang性能的误区/","link":"","permalink":"https://lintingbin2009.github.io/2017/10/14/efficiency-guide-七个Erlang性能的误区/","excerpt":"","text":"这些内容是有些是由于Erlang版本变化做的一些优化，和之前的有些要点有些出入，快速的扫一下即可 尾递归总是比普通递归来的快这个说法在R12B之前是真的。在R7B之前更是如此。但是现在普通递归通常使用与尾递归相同的内存量，通常不可能预测尾递归或身体递归版本是否更快。因此，使用使代码更清洁的版本就可以了（通常是普通递归的版本）。但是死循环还是要使用尾递归，防止内存耗尽。 “++” 操作总是不好的如果是这样[H] ++ Tail 使用 “++” 操作的话，没有什么不好的，编译器会自动把该操作转换成[H| Tail]。 字符串操作很慢如果不正确地使用字符串，字符串操作速度可能很慢。在Erlang中，需要更多地思考如何使用字符串并选择适当的字符表示。如果使用正则表达式，请使用STDLIB中的re模块，而不是过时的regexp模块。 修复Dets文件非常慢Dets文件的修复时间与文件中的记录数成正比，虽然Dets文件修复以前很慢，但是Dets的实现已被大量改写和改进。 BEAM是一个基于堆栈的字节码虚拟机（因此比较慢）BEAM是一个基于寄存器的虚拟机。它有1024个虚拟寄存器，用于保存临时值，并在调用函数时传递参数。需要在函数调用中使用的变量将保存到堆栈中。BEAM是一个线程代码解释器。每个指令是直接指向可执行C代码的字，使得指令调度非常快。 当变量不被使用时，使用“_”来加快程序速度这个在R6B版本之前是这样的，但是在这个版本之后，编译器能够自动识别不使用的变量，所以用不用“_”都一样。 NIF总是能使用你的程序更快将Erlang代码重写为NIF以使其更快，应该被视为最后的手段。使用NIF肯定有风险，但是不能保证程序能更快。在每个NIF调用中进行太多的工作会降低VM的响应能力。做太少的工作可能意味着NIF中更快处理的优势被调用NIF并检查参数的开销所抵消了。所以在写NIF之前，请务必阅读 Long-running NIFs 。","categories":[{"name":"Erlang Efficiency Guide","slug":"Erlang-Efficiency-Guide","permalink":"https://lintingbin2009.github.io/categories/Erlang-Efficiency-Guide/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"Erlang文档的efficiency_guide总结","slug":"Erlang文档的efficiency-guide总结","date":"2017-10-13T15:07:04.000Z","updated":"2017-10-14T09:21:34.785Z","comments":true,"path":"2017/10/13/Erlang文档的efficiency-guide总结/","link":"","permalink":"https://lintingbin2009.github.io/2017/10/13/Erlang文档的efficiency-guide总结/","excerpt":"","text":"之前刚开始学习的Erlang的时候稍微看过这个教程，但是没有看全，发现这个教程还涵盖了挺多的信息的，今天把这个教程看完，顺便做一下总结，教程原版地址 本来是想把所有的总结写在一篇文章里面的，但是由于篇幅比较大，所以就把所有的总结分为以下几篇文章: efficiency_guide:七个Erlang性能的误区 efficiency_guide:需要注意的模块和BIF efficiency-guide:Binary的构建和匹配 efficiency-guide:List处理","categories":[{"name":"Erlang Efficiency Guide","slug":"Erlang-Efficiency-Guide","permalink":"https://lintingbin2009.github.io/categories/Erlang-Efficiency-Guide/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"怎么实现一个Sublime的自动补全插件","slug":"怎么实现一个Sublime的自动补全插件","date":"2017-09-03T05:45:49.000Z","updated":"2017-10-07T07:29:23.152Z","comments":true,"path":"2017/09/03/怎么实现一个Sublime的自动补全插件/","link":"","permalink":"https://lintingbin2009.github.io/2017/09/03/怎么实现一个Sublime的自动补全插件/","excerpt":"","text":"使用Erlang开发了快三年的游戏了，一直使用的是Sublime编辑器，也就这样没有自动补全的情况下使用了三年，本来打算切换到有Erlang自动补全的Ide的，但是在Sublime上面开发了那么久，切换到其他的编辑器觉得很不习惯，所以就自己写了一个Erlang的自动补全的插件，点这里可以看到我的插件 Sublime插件是用Python写的，所以打算开发Sublime插件的话要稍微去学习下Python，不用学的很深入，懂得基本的语法就可以愉快的开始开发插件了。我之前的入门教程看的是creating-sublime-text-3-plugins-part-1，如果打算开发Sublime插件的话，看这篇文章就可以写一个简单的Sublime插件的Demo。这个网址api_reference可以查看开发Sublime插件所提供的各种API。 我写Erlang自动补全代码和自动跳转的原理是在打开Sublime的时候，扫描所有Erlang的源代码和Sublime中已经打开的所有的Erlang代码，然后利用正则表达式匹配来找出所有函数和模块所在的文件和位置，把这些信息都写入到Sqlite数据库中，然后在用户在编写Erlang源代码的时候提供补全的函数和模块。当用户把鼠标指向某个函数的时候，在Sqlite数据库中查询相应的函数所在的文件和位置，当用户选中的时候打开该文件并且定位到文件的相应的位置。具体的代码可以在点这里可以看到我的插件这里查看。当写好一个插件后我们最好能把插件放到Package Control中，这样用户安装和升级插件就会非常的方便，通过这个submitting_a_package教程能够顺利的提交自己的插件到Package Control中。 自己写一个小插件有时候还是可以学到一点东西的，通过这次编写自动补全的插件，让我对正则表达式稍微熟悉了一点。","categories":[{"name":"教程","slug":"教程","permalink":"https://lintingbin2009.github.io/categories/教程/"}],"tags":[{"name":"Sublime","slug":"Sublime","permalink":"https://lintingbin2009.github.io/tags/Sublime/"},{"name":"插件","slug":"插件","permalink":"https://lintingbin2009.github.io/tags/插件/"}]},{"title":"mochiweb的x-forwarded-for实现引发的线上掉单","slug":"mochiweb的x-forwarded-for实现引发的线上掉单","date":"2017-08-18T13:13:44.000Z","updated":"2017-08-18T13:18:16.342Z","comments":true,"path":"2017/08/18/mochiweb的x-forwarded-for实现引发的线上掉单/","link":"","permalink":"https://lintingbin2009.github.io/2017/08/18/mochiweb的x-forwarded-for实现引发的线上掉单/","excerpt":"","text":"记录一次线上充值服的掉单问题，同时学习下什么是x-forwarded-for 掉单原因？因为充值服都设有白名单，如果充值请求的机器的IP不在白名单里面的话会被视为非法IP，在掉单期间，线上的充值服发现有大量的100.116. . 的非法IP的访问，之后在网上一查，原来100.64.0.0/10也是属于内网IP的。我们的充值服务器使用了负载均衡，所以100.116..的IP应该是负载均衡机器的内网IP，同时由于我们充值服务器使用的是mochiweb的服务器，所以第一时间查看了下mochiweb获取IP的源代码：123456789101112131415161718192021222324252627282930313233343536get(peer, &#123;?MODULE, [Socket, _Opts, _Method, _RawPath, _Version, _Headers]&#125;=THIS) -&gt; case mochiweb_socket:peername(Socket) of &#123;ok, &#123;Addr=&#123;10, _, _, _&#125;, _Port&#125;&#125; -&gt; case get_header_value(\"x-forwarded-for\", THIS) of undefined -&gt; inet_parse:ntoa(Addr); Hosts -&gt; string:strip(lists:last(string:tokens(Hosts, \",\"))) end; %% Copied this syntax from webmachine contributor Steve Vinoski &#123;ok, &#123;Addr=&#123;172, Second, _, _&#125;, _Port&#125;&#125; when (Second &gt; 15) andalso (Second &lt; 32) -&gt; case get_header_value(\"x-forwarded-for\", THIS) of undefined -&gt; inet_parse:ntoa(Addr); Hosts -&gt; string:strip(lists:last(string:tokens(Hosts, \",\"))) end; &#123;ok, &#123;Addr=&#123;192, 168, _, _&#125;, _Port&#125;&#125; -&gt; case get_header_value(\"x-forwarded-for\", THIS) of undefined -&gt; inet_parse:ntoa(Addr); Hosts -&gt; string:strip(lists:last(string:tokens(Hosts, \",\"))) end; &#123;ok, &#123;&#123;127, 0, 0, 1&#125;, _Port&#125;&#125; -&gt; case get_header_value(\"x-forwarded-for\", THIS) of undefined -&gt; \"127.0.0.1\"; Hosts -&gt; string:strip(lists:last(string:tokens(Hosts, \",\"))) end; &#123;ok, &#123;Addr, _Port&#125;&#125; -&gt; inet_parse:ntoa(Addr); &#123;error, enotconn&#125; -&gt; exit(normal) end; 从上面的代码可以看出，如果在服务器内网里面使用了代理服务器之后，mochiweb是能够自动获取原始的访问IP。但是仅限内网代理服务器的IP是一些常见的内网IP，100.64.0.0/10段的IP地址并不包括在里面，所以这时候获取的IP就不是原始IP，而是负载均衡机器的内网IP。 内网IP段有哪些？10.0.0.0/810.0.0.0 - 10.255.255.255 172.16.0.0/12172.16.0.0 - 172.31.255.255 192.168.0.0/16192.168.0.0 - 192.168.255.255 以上三个网段分别属于A、B、C三类IP地址 100.64.0.0/10100.64.0.0 - 100.127.255.255由运营商使用的私网IP段，随着IPv4地址池的耗光，会有更多用户被分配到这个网段。我们的线上掉单问题就是因为阿里云把内网IP切换到这个网段造成的。 http协议头标：x-forwarded-forX-Forwarded-For(XFF)是用来识别通过HTTP代理或负载均衡方式连接到Web服务器的客户端最原始的IP地址的HTTP请求头字段。 Squid 缓存代理服务器的开发人员最早引入了这一HTTP头字段，并由IETF在Forwarded-For HTTP头字段标准化草案中正式提出。 总结这次的掉单问题算起来应该算是一个不太能够发现的坑，主要是依赖第三方库的实现，我们这边相关的同事已经把修复代码提交pull request到mochiweb的github主页了，防止有更多的人碰到这个坑。","categories":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/categories/Erlang/"}],"tags":[{"name":"mochiweb","slug":"mochiweb","permalink":"https://lintingbin2009.github.io/tags/mochiweb/"},{"name":"x-forwarded-for","slug":"x-forwarded-for","permalink":"https://lintingbin2009.github.io/tags/x-forwarded-for/"}]},{"title":"基于Erlang的全区服分数竞技场的设计的优化","slug":"基于Erlang的全区服分数竞技场的设计的优化","date":"2017-07-13T13:47:51.000Z","updated":"2017-07-13T14:40:30.539Z","comments":true,"path":"2017/07/13/基于Erlang的全区服分数竞技场的设计的优化/","link":"","permalink":"https://lintingbin2009.github.io/2017/07/13/基于Erlang的全区服分数竞技场的设计的优化/","excerpt":"","text":"在上一篇文章Erlang动态代码载入小实验中，我提到的竞技场设计中存在一些性能问题，这篇文章主要是针对上一篇文章提到的性能问题在整体设计方案不进行大改的情况下进行优化。 主要性能问题回顾上一篇文章，我们知道之前的设计方案的主要问题是：频繁的在分数ETS中拿取和更新新的玩家List，而且该List的大小有可能是几十万的级别的，主要的性能问题是ETS和排行榜进程之间的数据拷贝。 在同一分数段的所有玩家都用List来存储的话，每次在一个分数中增加一个玩家的代价是，先从ets中lookup拿出所有这一分数的玩家，然后在这个列表中增加新的玩家，最后再把新的玩家列表更新回去，删除也是如此。如果每个分数的玩家列表都不是很大的话，这个应该问题也不会很大，但是由于同一分数段的玩家比较多，所以这个方案的性能就很差了。 优化一既然主要的性能问题出在List的更新和删除的操作，所以这个优化方案的主要方法是把List替换成ETS，当List的长度大于N(N可以自己设置，比如100、200之类)时，同一分数的所有玩家都存储在ETS中，这样在一个分数的玩家列表中增加一个玩家也只是在ETS中增加一个玩家ID而已，删除一个玩家的话，也只是在ETS中删除一个玩家ID，这两个操作都非常的快。 经过这一次的优化，竞技场玩家已经可以在正式环境中上线，但是在游戏最高峰的时间段，玩家还是会有点卡，此时游戏服务器（16核）的cpu几乎全部跑满，所以还需要进一步的优化。 优化二通过上一次优化我们知道，服务器在高峰的时候几乎把cpu全部跑满。这时候我就开始怀疑寻找对手的算法是否有问题，之前寻找对手都是现算的，把玩家的对手的排名算出来，然后在分数的ETS里面开始从头到尾遍历所有分数，找出符合对手排名的玩家。这样子寻找一个玩家的三个对手，大概要遍历分数ETS一千多次，在平时的时候还是非常快的，下面是我用eprof测量的在平时寻找一次对手的一些关键操作的开销：1234legend_arena_global_rank:query_apprentice_rank/7 389 4.25 290 [ 0.75]legend_arena_global_rank:query_apprentice_key/3 1076 7.45 508 [ 0.47]ets:lookup_element/3 1465 34.31 2340 [ 1.60]ets:prev/2 1459 45.52 3105 [ 2.13] 再下面的是我用eprof测试的在小高峰期寻找一次对手的一些关键操作的开销：1234legend_arena_global_rank:query_apprentice_rank/7 386 1.16 216 [ 0.56]legend_arena_global_rank:query_apprentice_key/3 1029 2.95 551 [ 0.54]ets:lookup_element/3 1415 39.47 7371 [ 5.21]ets:prev/2 1409 54.38 10157 [ 7.21] 通过上面两次的测量可以看到：分数ETS在大量访问的时候出现了性能下降，本来ets:prev/2操作只需要2.13us，在高峰期居然需要7.21us；本来ets:lookup_element/3操作只需要1.6us，在高峰期居然需要5.21us。 所以这次的主要优化方法是把对分数ETS的访问次数降下来，建立一些排名的缓存，当一个玩家寻找对手的时候直接在缓存中寻找，同时每秒钟刷新一次缓存（确保排名比较正确）。这样不管是在高峰期还是平时，分数ETS都不会有非常明显的访问量的提升。 总结通过这次的优化，我认为不管用什么语言来实现一个系统，都要了解这个语言的优势和劣势，这样才能找出一个合理的解决方案来解决一些比较棘手的问题。","categories":[{"name":"算法设计","slug":"算法设计","permalink":"https://lintingbin2009.github.io/categories/算法设计/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"设置Shell脚本执行错误自动退出","slug":"设置Shell脚本执行错误自动退出","date":"2017-07-06T13:44:10.000Z","updated":"2017-07-06T14:06:03.521Z","comments":true,"path":"2017/07/06/设置Shell脚本执行错误自动退出/","link":"","permalink":"https://lintingbin2009.github.io/2017/07/06/设置Shell脚本执行错误自动退出/","excerpt":"","text":"这是一篇备忘记录，以后再写Shell脚本的时候需要注意！ 之前项目使用Jenkins打包的时候，有时候因为一些错误的提交，导致出包的时候编译失败，从而导致打包出来的包里面只有部分的代码，这是因为我们写的Shell脚本没有对每条Shell命令的结果进行检查，不管执行结果是否成功都会继续往下执行。所以即使我们在编译环节有错误产生，打包的脚本还是会继续执行后面的打包指令。所以必须让脚本在某条命令执行失败的时候停止执行后续的指令。在Shell脚本中加入： #!/bin/bash -e或者set -e 就能够让脚本在有错误的时候退出。下面是网上查的拓展： 使用set -e123456789你写的每一个脚本的开始都应该包含set -e。这告诉bash一但有任何一个语句返回非真的值，则退出bash。 使用-e的好处是避免错误滚雪球般的变成严重错误，能尽早的捕获错误。更加可读的版本：set -o errexit 使用-e把你从检查错误中解放出来。如果你忘记了检查，bash会替你做这件事。不过你也没有办法使用$? 来获取命令执行状态了，因为bash无法获得任何非0的返回值。你可以使用另一种结构，使用command 使用command123456789101112131415if [ \"$?\"-ne 0]; then echo \"command failed\"; exit 1; fi \"可以替换成： command || echo \"command failed\"; exit 1; （这种写法并不严谨，我当时的场景是执行ssh \"commond\"，所以可以返回退出码后面通过[ #？ -eq 0 ]来做判断，如果是在shell中无论成功还是失败都会exit）修改如下（谢谢评论的朋友指正）command || （echo \"command failed\"; exit 1） ; 或者使用： if ! command; then echo \"command failed\"; exit 1; fi","categories":[{"name":"备忘","slug":"备忘","permalink":"https://lintingbin2009.github.io/categories/备忘/"}],"tags":[{"name":"Shell","slug":"Shell","permalink":"https://lintingbin2009.github.io/tags/Shell/"}]},{"title":"基于Erlang的全区服分数竞技场的设计","slug":"基于Erlang的全区服分数竞技场的设计","date":"2017-06-19T13:38:56.000Z","updated":"2017-06-19T15:19:16.998Z","comments":true,"path":"2017/06/19/基于Erlang的全区服分数竞技场的设计/","link":"","permalink":"https://lintingbin2009.github.io/2017/06/19/基于Erlang的全区服分数竞技场的设计/","excerpt":"","text":"这篇文章主要介绍我之前开发的一个基于Erlang的全区服分数竞技场的设计思路，同时会给出该设计的在现实项目中出现的问题，并且在后续的几篇文章中优化设计。 关键需求该分数竞技场的实际需求比较多，这边只列举对我们设计有影响的几个关键需求，以下是该分数竞技场的关键需求： 每个玩家拥有一个分数，该分数大概是6000以内的数字。 玩家要实时知道自己的分数和排名。 玩家可以手动刷新自己的对手，玩家的对手由于玩家的排名乘以30%、60%、90%左右的排名的玩家随机出来。比如一个1000名的玩家，他的对手可能是由278、632、945名次的玩家组成。 玩家挑战对手，如果战胜，则玩家自己加分，对手扣分，反之亦然。 该竞技场每天在某一时间点进行结算发奖。 玩家数量级玩家的数量级有两个，分别是测试环境和正式环境： 测试环境的玩家帐号有几十万，日活是2万左右。 正式环境的玩家帐号有几百万，日活是60万左右。 设计思路下面介绍该分数竞技场的具体设计思路: 由于该竞技场是采用分数来排名，而且分数的区间比较小，所以我想到了使用桶排序来对玩家分数排名。 由于该竞技场是所有玩家共同访问的，所以打算用ETS来实现这个桶排序。 由于分数需要是有序存储的，所以该ETS为ordered_set类型，而且Key为分数，Value有两个字段： list——存储该分数的所有玩家的key cnt——存储该分数的玩家总数 玩家的排名为：从该分数ETS分数最大的元素开始遍历，遍历到玩家所在的分数的前一个分数，在遍历的同时累加遍历到的cnt值，玩家的排名为累加值加1，同一分数玩家的排名一致。例如：玩家分数为5000分，在5000分之前有100个5020分，1个5500分，则玩家为第102名。 当玩家进行一场挑战的时候，把玩家key从他原来的分数list里面移除，并且该分数的cnt-1；同时把玩家key加入到新的分数的list，并且该新分数的cnt+1；对手的分数改变也是进行同样的操作；这些操作在gen_server中进行，确保数据不会被脏写。 运行结果 该设计在测试环境中测试通过了，而且没有发现什么异常。 在正式环境中，只有少量玩家访问的情况下，访问时间到达几秒的级别，只能暂时关闭该功能进行优化。 主要问题这边列举两个比较严重的问题： 同一分数的玩家数量很多，同一分数最多的玩家有50万人,使用list来存储玩家的key，每次对这个list增删代价巨大。 由于ETS是另外一个单独的进程，每次从ETS中拿一个50万人的list，然后再把新的list更新回去，代价同样巨大。 主要优化目标由于留给优化的时间比较短，所以要在原有的设计思路下对该分数竞技场进行优化，达到能够上线的标准。","categories":[{"name":"算法设计","slug":"算法设计","permalink":"https://lintingbin2009.github.io/categories/算法设计/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"Markdown语法速记","slug":"Markdown语法速记","date":"2017-06-17T14:44:26.000Z","updated":"2017-06-17T16:21:19.489Z","comments":true,"path":"2017/06/17/Markdown语法速记/","link":"","permalink":"https://lintingbin2009.github.io/2017/06/17/Markdown语法速记/","excerpt":"","text":"有时候自己也会忘记Markdown的语法，在这边做一个备忘，以后找起来比较方便，这边记录的是最基本的Markdown语法。 粗体和斜体1_下划线是斜体_ 下划线是斜体1**两个星是粗体** 两个星是粗体1**_粗体斜体一起用_** 粗体斜体一起用 六种标题几个#号代表标题几,#号后面有空格123456# 标题1## 标题2### 标题3#### 标题4##### 标题5###### 标题6 链接123456这是一个 [普通的链接方式](https://www.github.com)这是一个 [引用的链接方式][another place].这还是一个 [引用的链接方式][another-link].[another place]: https://www.github.com[another-link]: https://www.google.com 这是一个 普通的链接方式这是一个 引用的链接方式.这还是一个 引用的链接方式. 图片1234![我的头像](https://lintingbin2009.github.io/img/avatar.jpg)![又是一个头像][other][other]: https://lintingbin2009.github.io/img/avatar.jpg 我的头像 引用123&gt;在要被引用的段落或者行前面加大括号&gt;&gt;即使是空行也要加一下，保持一致 在要被引用的段落或者行前面加大括号 即使是空行也要加一下，保持一致 列表123451. 有序用数字 继续保持缩进,只需加空格2. 有序用数字 * 无序用星号 * 还可再缩进,只需再加空格 有序用数字继续保持缩进,只需加空格 有序用数字 无序用星号 还可再缩进,只需再加空格 段落12我在逗号后加了两个空格, 所以不在一行 我在逗号后加了两个空格,所以不在一行","categories":[{"name":"教程","slug":"教程","permalink":"https://lintingbin2009.github.io/categories/教程/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://lintingbin2009.github.io/tags/Markdown/"}]},{"title":"Erlang中由rpc:cast错误引起的对error_logger的研究","slug":"Erlang中由rpc-cast错误引起的对error-logger的研究","date":"2017-06-15T14:45:28.000Z","updated":"2017-06-17T04:16:01.605Z","comments":true,"path":"2017/06/15/Erlang中由rpc-cast错误引起的对error-logger的研究/","link":"","permalink":"https://lintingbin2009.github.io/2017/06/15/Erlang中由rpc-cast错误引起的对error-logger的研究/","excerpt":"","text":"之所以会写这篇文章，是因为rpc:cast函数的使用超出了我的理解范围，本来我的理解是：如果rpc:cast执行失败的话，是不会有任何报错的。但是由于最近的线上存在两个版本的代码进行的互相调用引发了一些报警，让我好奇rpc:cast和error_logger是怎么工作的。 rpc:cast 是怎么工作的？我们在查阅rpc的源代码的时候可以发现以下代码：12345678910111213141516-define(NAME, rex)....handle_cast(&#123;cast, Mod, Fun, Args, Gleader&#125;, S) -&gt; spawn(fun() -&gt; set_group_leader(Gleader), apply(Mod, Fun, Args) end), &#123;noreply, S&#125;;...cast(Node, Mod, Fun, Args) when Node =:= node() -&gt; catch spawn(Mod, Fun, Args), true;cast(Node, Mod, Fun, Args) -&gt; gen_server:cast(&#123;?NAME,Node&#125;, &#123;cast,Mod,Fun,Args,group_leader()&#125;), true.... 从上面的代码我们可以看到，rpc:cast的时候如果目标node和本地node一样的话就会直接spawn一个进程处理，如果是远程的话，则会调用一个名字为rex的gen_server到远程的服务器上执行，远程的服务器同样也是spawn一个进程来处理。如果一个服务器是为其他服务器提供服务的（通过rpc模块），那么这个服务器的rex应该会是最繁忙的。通过上面的分析我们知道rpc:cast的错误是spawn函数通知error_logger的。 spawn出来的进程执行遇到错误怎么处理？我自己试验了下，比如我自己在shell里面执行spawn(fun() -&gt; 1 = 2 end).语句的话，error_logger就会收到如下的一个错误事件：123&#123;error,&lt;113291.32.0&gt;, &#123;emulator,\"~s~n\", [\"Error in process &lt;0.13313.2075&gt; on node 'all_in_one_33000@192.168.1.102' with exit value: &#123;&#123;badmatch,2&#125;,[&#123;erl_eval,expr,3,[]&#125;]&#125;\\n\"]&#125;&#125; 为了明白上述的情况为什么会发生，我在Erlang邮件列表里面找到两个类似的问题，可以解答我的疑问： [erlang-questions] An answer: how does SASL know that a process died? [erlang-questions] error_logger events sent by emulator 简单的总结上面的两个问题，spawn执行的程序遇到异常的话，是由虚拟机的C语言代码向error_logger发送的错误事件。 error_logger 是怎么工作的？error_logger是Erlang的错误记录器，由gen_event实现，在Erlang系统中会有一个注册名为error_logger的事件管理器(event manager)，可以在事件管理器中加入各种处理模块来处理事件。默认的系统中会加入以下两个错误处理模块：1234567$ erlErlang R16B03 (erts-5.10.4) [source] [64-bit] [smp:12:12] [async-threads:10] [hipe] [kernel-poll:false]Eshell V5.10.4 (abort with ^G)1&gt; gen_event:which_handlers(error_logger).[error_logger,error_logger_tty_h] 简单的说下这两个错误处理模块，首先是error_logger模块，以下是该模块的处理事件的部分代码：123456789101112131415161718192021handle_event(&#123;Type, GL, Msg&#125;, State) when node(GL) =/= node() -&gt; gen_event:notify(&#123;error_logger, node(GL)&#125;,&#123;Type, GL, Msg&#125;), %% handle_event2(&#123;Type, GL, Msg&#125;, State); %% Shall we do something &#123;ok, State&#125;; %% at this node too ???handle_event(&#123;info_report, _, &#123;_, Type, _&#125;&#125;, State) when Type =/= std_info -&gt; &#123;ok, State&#125;; %% Ignore other info reports herehandle_event(Event, State) -&gt; handle_event2(Event, State)....handle_event2(Event, &#123;1, Lost, Buff&#125;) -&gt; display(tag_event(Event)), &#123;ok, &#123;1, Lost+1, Buff&#125;&#125;;handle_event2(Event, &#123;N, Lost, Buff&#125;) -&gt; Tagged = tag_event(Event), display(Tagged), &#123;ok, &#123;N-1, Lost, [Tagged|Buff]&#125;&#125;;handle_event2(_, State) -&gt; &#123;ok, State&#125;....display2(Tag,F,A) -&gt; erlang:display(&#123;error_logger,Tag,F,A&#125;). 该模块把是本node产生的事件调用erlang:display()输出，把不是本node产生的事件发送到目标node上面，由目标node的error_logger进行处理。 接着是error_logger_tty_h模块，以下是该模块的处理事件的部分代码：12345678910111213141516171819handle_event(&#123;_Type, GL, _Msg&#125;, State) when node(GL) =/= node() -&gt; &#123;ok, State&#125;;handle_event(Event, State) -&gt; write_event(tag_event(Event),io), &#123;ok, State&#125;....write_event(&#123;Time, &#123;error, _GL, &#123;Pid, Format, Args&#125;&#125;&#125;,IOMod) -&gt; T = write_time(maybe_utc(Time)), case catch io_lib:format(add_node(Format,Pid), Args) of S when is_list(S) -&gt; format(IOMod, T ++ S); _ -&gt; F = add_node(\"ERROR: ~p - ~p~n\", Pid), format(IOMod, T ++ F, [Format,Args]) end;...format(IOMod, String) -&gt; format(IOMod, String, []).format(io_lib, String, Args) -&gt; io_lib:format(String, Args);format(io, String, Args) -&gt; io:format(user, String, Args). 该模块把不是该node的事件直接忽略，然后把本node的事件调用io:format输出到终端上面。 除了这两个处理模块，Erlang的sasl应用还提供了三个模块：sasl_report_tty_h、sasl_report_file_h、log_mf_h。log_mf_h模块的功能最为强大，能够把错误写入指定个数的文件中，当文件用完后会自动删除最老的事件以腾出空间记录最新的事件。但是log_mf_h的缺点是记录的是二进制的格式，要查看记录的事件的话，还需要使用sasl提供的rb模块来解析，颇为繁琐。而且该模块没有对单事件的最大上限做保护，如果有超大的事件写入的话，就会导致文件错乱，看不了事件（这个可以自己写代码做保护，我们项目之前就是这样做的）。 当然除了官方提供的处理模块，也可以使用第三方提供的模块。现在我们项目就把所有官方提供的模块都删除掉了，只使用lager提供的error_logger_lager_h模块来处理事件，然后自己编写了一个alarm_handle_error模块用来发送报警。error_logger_lager_h使用文本的方式来记录事件，查看起来比较方便，而且对Erlang内部一些比较难以理解的错误进行翻译，比较容易理解；但是由于使用文本的方式进行记录，没有对事件消息进行格式化，如果消息比较大的话，读起来比较费劲。 error_logger 添加处理模块的注意事项当使用sasl提供的log_mf_h处理模块的时候不能删除系统提供的error_logger模块，不然像rpc:cast通知的事件就不能正常的捕获了，原因如下：123456%% 当NodeA执行以下函数的时候，在NodeB会接收到一个错误，%% 由于NodeB只有log_mf_h模块，log_mf_h模块会对接收的事件使用sasl:pred/1函数进行过滤%% sasl:pred/1会过滤不是本node的产生的事件，因此该错误被过滤%% 如果这时候NodeB有error_logger模块的话，error_logger模块就会将事件通知NodeA%% 然后NodeA就能使用log_mf_h模块正确记录该错误，该错误记录在NodeA的机器上NodeA: rpc:cast(NodeB, M, ErrorFun, []). lager的error_logger_lager_h模块默认会记录所有的事件，不管该事件是属于哪个Node的，如下：123%% 当NodeA执行以下函数的时候，在NodeB会接收到一个错误，%% error_logger_lager_h直接记录错误在NodeB的机器上NodeA: rpc:cast(NodeB, M, ErrorFun, []). 最后说两句之前项目使用log_mf_h模块处理事件的配置文件如下：1234567[&#123;sasl, [ &#123;sasl_error_logger, false&#125;, &#123;errlog_type, error&#125;, &#123;error_logger_mf_dir, \"logs\"&#125;, &#123;error_logger_mf_maxbytes, 1073741824&#125;, % 1GB &#123;error_logger_mf_maxfiles, 10&#125; ]&#125;]. 之前一直觉得errlog_type是控制log_mf_h模块的处理事件级别的参数，这边设置的参数是error，为什么info的信息还会记录下来呢？后面看了下sasl.erl模块的代码，errlog_type和log_mf_h模块根本没有关系，然后回头再看了一下sasl的文档: log_mf_h This error logger writes all events sent to the error logger to disk. Multiple files and log rotation are used. For efficiency reasons, each event is written as a binary. For more information about this handler, see the STDLIB Reference Manual. To activate this event handler, three SASL configuration parameters must be set, error_logger_mf_dir, error_logger_mf_maxbytes, and error_logger_mf_maxfiles. The next section provides more information about the configuration parameters. 文档中all已经加黑了，我居然没看到，以后还得好好认真看文档！","categories":[{"name":"Erlang深入","slug":"Erlang深入","permalink":"https://lintingbin2009.github.io/categories/Erlang深入/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"使用lager为什么要加入编译选项{parse_transform,lager_transform}","slug":"使用lager为什么要加入编译选项-parse-transform-lager-transform","date":"2017-05-30T05:03:05.000Z","updated":"2017-06-17T04:12:51.109Z","comments":true,"path":"2017/05/30/使用lager为什么要加入编译选项-parse-transform-lager-transform/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/30/使用lager为什么要加入编译选项-parse-transform-lager-transform/","excerpt":"","text":"在使用的lager的时候我们需要加入一行编译选项——{parse_transform,lager_transform}，或者是在每个使用lager的文件模块的头部加入一行-compile([{parse_transform, lager_transform}]).，这通常会让我们感觉非常的麻烦，但是大家有没有觉得好奇，为什么使用这个参数呢？ 首先我们看下Erlang文档，在compile模块中有parse_transform参数的相关说明： {parse_transform,Module}Causes the parse transformation function Module:parse_transform/2 to be applied to the parsed code before the code is checked for errors. 通过上面的文档我们知道，在编译的时候使用{parse_transform,Module}参数，会使用Module:parse_transform/2函数对代码进行一次解析转换。接下来我们在lager的源代码目录下可以看到lager_transform.erl的代码文件，里面也有一个parse_transform/2的函数。1234567891011parse_transform(AST, Options) -&gt; TruncSize = proplists:get_value(lager_truncation_size, Options, ?DEFAULT_TRUNCATION), Enable = proplists:get_value(lager_print_records_flag, Options, true), Sinks = [lager] ++ proplists:get_value(lager_extra_sinks, Options, []), put(print_records_flag, Enable), put(truncation_size, TruncSize), put(sinks, Sinks), erlang:put(records, []), %% .app file should either be in the outdir, or the same dir as the source file guess_application(proplists:get_value(outdir, Options), hd(AST)), walk_ast([], AST). parse_transform/2函数的第一个参数是AST，这个是代码在被编译成二进制前的一种格式The Abstract Format,第二个参数是在编译的时候传入的编译参数，比如要加入一个sink的话不单单要在配置文件里面加入配置，还要在编译参数里面加入{lager_extra_sinks, [audit]}，这样parse_transform/2函数才能在proplists:get_value(lager_extra_sinks, Options, [])的时候获得audit这个sink。 顺着代码往下走，我们看到只有调用的函数的模块名是Sinks中之一的才会被解析转换（lists:member(Module, Sinks)），比如lager:info、lager:error、audit:info、audit:error等函数（audit为我们配置的sink）。1234567891011121314151617181920212223242526walk_body(Acc, []) -&gt; lists:reverse(Acc);walk_body(Acc, [H|T]) -&gt; walk_body([transform_statement(H, get(sinks))|Acc], T).transform_statement(&#123;call, Line, &#123;remote, _Line1, &#123;atom, _Line2, Module&#125;, &#123;atom, _Line3, Function&#125;&#125;, Arguments0&#125; = Stmt, Sinks) -&gt; case lists:member(Module, Sinks) of true -&gt; case lists:member(Function, ?LEVELS) of true -&gt; SinkName = lager_util:make_internal_sink_name(Module), do_transform(Line, SinkName, Function, Arguments0); false -&gt; case lists:keyfind(Function, 1, ?LEVELS_UNSAFE) of &#123;Function, Severity&#125; -&gt; SinkName = lager_util:make_internal_sink_name(Module), do_transform(Line, SinkName, Severity, Arguments0, unsafe); false -&gt; Stmt end end; false -&gt; list_to_tuple(transform_statement(tuple_to_list(Stmt), Sinks)) end; 最后来到解析转换真正起作用的地方，这边的注释写的很清楚，下面的解析转换等于就是lager:dispatch_log/6里面的内容，如果直接调用lager:dispatch_log/6函数的话，是不需要这样的解析转换的，我对此特地问了下lager的开发者，这样做的话能够提高多少的性能，对方给的答复是能快一倍（图 1-1），因为在log不需要输出的情况下就不需要拷贝内容到外部的函数了，个人觉得一次外部函数调用应该费不了多少时间吧。1234567891011121314151617181920212223242526272829%% Wrap the call to lager:dispatch_log/6 in case that will avoid doing any work if this message is not elegible for logging%% See lager.erl (lines 89-100) for lager:dispatch_log/6%% case &#123;whereis(Sink), whereis(?DEFAULT_SINK), lager_config:get(&#123;Sink, loglevel&#125;, &#123;?LOG_NONE, []&#125;)&#125; of&#123;'case',Line, &#123;tuple,Line, [&#123;call,Line,&#123;atom,Line,whereis&#125;,[&#123;atom,Line,SinkName&#125;]&#125;, &#123;call,Line,&#123;atom,Line,whereis&#125;,[&#123;atom,Line,?DEFAULT_SINK&#125;]&#125;, &#123;call,Line, &#123;remote,Line,&#123;atom,Line,lager_config&#125;,&#123;atom,Line,get&#125;&#125;, [&#123;tuple,Line,[&#123;atom,Line,SinkName&#125;,&#123;atom,Line,loglevel&#125;]&#125;, &#123;tuple,Line,[&#123;integer,Line,0&#125;,&#123;nil,Line&#125;]&#125;]&#125;]&#125;, %% &#123;undefined, undefined, _&#125; -&gt; &#123;error, lager_not_running&#125;; [&#123;clause,Line, [&#123;tuple,Line, [&#123;atom,Line,undefined&#125;,&#123;atom,Line,undefined&#125;,&#123;var,Line,'_'&#125;]&#125;], [], %% trick the linter into avoiding a 'term constructed but not used' error: %% (fun() -&gt; &#123;error, lager_not_running&#125; end)() [&#123;call, Line, &#123;'fun', Line, &#123;clauses, [&#123;clause, Line, [],[], [&#123;tuple, Line, [&#123;atom, Line, error&#125;,&#123;atom, Line, lager_not_running&#125;]&#125;]&#125;]&#125;&#125;, []&#125;] &#125;, %% &#123;undefined, _, _&#125; -&gt; &#123;error, &#123;sink_not_configured, Sink&#125;&#125;; &#123;clause,Line, [&#123;tuple,Line, [&#123;atom,Line,undefined&#125;,&#123;var,Line,'_'&#125;,&#123;var,Line,'_'&#125;]&#125;], [], %% same trick as above to avoid linter error [&#123;call, Line, &#123;'fun', Line, &#123;clauses, [&#123;clause, Line, [],[], [&#123;tuple,Line, [&#123;atom,Line,error&#125;, &#123;tuple,Line,[&#123;atom,Line,sink_not_configured&#125;,&#123;atom,Line,SinkName&#125;]&#125;]&#125;]&#125;]&#125;&#125;, []&#125;] &#125;, %% &#123;SinkPid, _, &#123;Level, Traces&#125;&#125; when ... -&gt; lager:do_log/9; 图 1-1 总结一下，我们平时在用Erlang编程的时候应该不会涉及到自己编写parse_transform函数的需求，这个函数的功能非常强大，可以理解成是一个功能非常强大的宏，但是我觉得编写这个函数的话也会非常容易出错的，看下lager_transform.erl文件里面的代码就知道了。其实不单单lager使用了parse_transform函数的功能，ets也使用了这个功能，由于ets的select和match匹配的可读性实在太差了，所以可以使用ets:fun2ms/1模拟函数的写法来写匹配规则（当然不是真正的函数了，写起来有很多限制的），然后在编译的时候转化成select和match的匹配格式。","categories":[{"name":"Erlang深入","slug":"Erlang深入","permalink":"https://lintingbin2009.github.io/categories/Erlang深入/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"},{"name":"Lager","slug":"Lager","permalink":"https://lintingbin2009.github.io/tags/Lager/"}]},{"title":"Erlang垃圾回收","slug":"Erlang垃圾回收","date":"2017-05-21T05:02:42.000Z","updated":"2017-06-17T04:12:54.757Z","comments":true,"path":"2017/05/21/Erlang垃圾回收/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/21/Erlang垃圾回收/","excerpt":"","text":"由于Erlang的官方文档并没有介绍垃圾回收机制，本文参考一些论文和博客试着来解释下Erlang的内存回收机制，如果有存在错误，欢迎指正。 要解释Erlang的垃圾回收机制必须先知道Erlang的内存管理，在Erlang中存在三种架构来实现不同的内存管理方式，在之前的很长一段时间内用的都是process-centric的架构，现在不知道有没有改成Hybrid，没有找到相关的说明文档。接下来分别介绍下这三种架构： 图1 Hybrid架构内存组织 Process-centric在该架构中，进程间通信需要复制消息，因此是O(n)操作，其中n是消息大小。内存碎片通常比较多。预计垃圾回收的时间和次数预计会很小（因为根集只需要堆叠的进程需要收集），并且在进程终止之后，其分配的内存区域可以在不间断的时间内被回收。在图1中相当于没有Shared Heap区域。 Communal这种架构的最大的优点是非常快（O(1)）的通信，只需将指针传递给接收进程，由于消息共享，所以内存的需求也比较小，并且分散性低。缺点在于，必须将所有进程的堆栈作为根集的一部分（导致增加GC延迟），并且由于进程的数据在共享堆上交错而导致可能的缓存性能差。此外，这种架构不能很好地扩展到多线程或多处理器实现，因为需要锁定以便以并行设置分配和收集共享存储器区域。简单的说所有的消息都是共享的，进程内只存了指针。 Hybrid这是一种尝试结合上述两个架构的优点的架构：进程间通信可能很快，并且进程本地堆的频繁收集的GC延迟预计会很小。对进程本地堆的垃圾收集不需要锁定，并且减少了共享堆上的压力，因此它不需要经常进行垃圾回收。而且，像Process-centric架构一样，当一个进程终止时，它的本地内存可以通过简单地将其附加到自由列表（free-list）来回收。图1是该架构的内存组织图。 由于之前Erlang里面默认采用的是Process-centric的架构，所以我们这边介绍Process-centric架构的内存回收方式，如果想要了解Hybrid的内存回收方式可以参考《Message Analysis-Guided Allocation and Low-Pause》这篇论文。 Process-centric架构由于没有Shared Heap，所以内存回收只涉及到进程的内存回收和Shared Area for Binaries的内存回收。 进程内存回收如图1所示，Erlang的进程和Linux的进程非常的像，由进程控制块（PCB）、堆（Stack）和栈（Heap）组成。 进程控制块：进程控制模块会保存一些关于进程的信息比如它在进程表中的标识符（PID）、当前状态（运行、等待）、它的注册名、初始和当前调用，同时PCB也会保存一些指向传入消息的指针，这些传入消息是存储在堆中连接表中的。 栈：它是一个向下增长的存储区，这个存储区保存输入和输出参数、返回地址、本地变量和用于执行表达式的临时空间。 堆：它是一个向上增长的存储区，这个存储区保存进程邮箱的物理消息，像列表、元组和Binaries这种的复合项以及比像浮点数这种一个机器字更大的对象。超过64机器字的二进制项不会存储在进程私有堆里，而是被存在图1的Shared Area for Binaries里面，进程堆维护一个列表（remembered list），该列表存储该进程指向Shared Area for Binaries区域的所有指针。 进程的内存回收机制采用的是分代标记清除(“stop the world” generational mark-sweep collector)的回收机制，通过这种机制把进程堆划分为了一个老年代（Old Generation）和新生代（Young Generation），使用minor collection对新生代进行垃圾回收，major collection进行整个堆的垃圾回收。进程垃圾回收的时候该进程会卡住，但是由于进程堆的大小一般都比较小所以回收的很快，而且这时候其他进程也在运行，所以垃圾回收不太会影响系统的响应能力。进程创建后的首次垃圾回收会使用major collection，后面在进程运行的过程中如果发现内存不够用的话会先使用minor collection进行回收，如果还是不能释放出足够的空间的话则会使用major collection进行回收，然后如果major collection还是不能释放出足够的空间的话，则会增加进程堆的大小。进程默认的min_heap_size的大小是233个字，进程堆大小的增长策略首先是斐波纳契序列增长，当堆的大小到达1.3M个字的时候堆每次只增长20%。 Shared Area for Binaries内存回收这个区域的内存回收采用的是标记清除的方法，在每个Binary的头部上会有一个数字，记录着这个Binary被引用了几次。在进程结束之后，进程堆中的remembered list的指针指向的Binary的引用次数会被相应的减1，同样在进程垃圾回收的时候如果发现remembered list中有可以被回收的指针，该指针所指向的Binary的引用次数也会被相应的减1，当一个Bianry的引用次数为0时，这个Binary就可以被回收。 建议通过了解Erlang垃圾回收的原理，可以在垃圾回收方面对系统进行一些调优，以及减少系统的内存使用量，以下是我总结的一些建议： 进程默认的min_heap_size的大小是233个字，如果能提前知道进程大概需要多少空间的话，在进程创建的时候指定min_heap_size的大小可以减少内存回收的次数。 由于进程内存回收是每个进程单独进行的，所以有些进程在申请了很多空间之后，很久没有运行，但是上次申请的空间其实有些已经没用了，如果进程一直不运行或者不触发回收，这部分内存就一直回收不了，这时候就需要手动的进行内存回收。建议可以定时执行以下代码进行内存回收： 12[erlang:garbage_collect(P) || P &lt;- erlang:processes(), &#123;status, waiting&#125; =:= erlang:process_info(P, status)], 我所在的项目在每次启动的时候都会进行大量的初始化，在项目启动成功后对所有进程一次手动回收也可以节省很多内存。 对一些重量级的操作可以spawn一个进程出来处理，当进程结束后该部分空间就能被完全回收了，比在原进程上面执行应该会好些。 之前看到一个开源项目在处理完一个请求后就对该进程进行一次手动回收，这个好像也是一个优化，因为一个请求过后再上来一个请求的话，可能需要秒的级别，进程在这段空闲时间进行一次回收不会影响系统的响应而且还能节省内存。","categories":[{"name":"Erlang深入","slug":"Erlang深入","permalink":"https://lintingbin2009.github.io/categories/Erlang深入/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"},{"name":"GC","slug":"GC","permalink":"https://lintingbin2009.github.io/tags/GC/"}]},{"title":"编程语言的垃圾回收机制简介","slug":"编程语言的垃圾回收机制简介","date":"2017-05-09T03:00:47.000Z","updated":"2017-05-09T03:52:38.940Z","comments":true,"path":"2017/05/09/编程语言的垃圾回收机制简介/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/09/编程语言的垃圾回收机制简介/","excerpt":"","text":"现在的编程语言中大多都包括了垃圾回收（Garbage Collection）机制，垃圾回收机制是一种自动的内存管理机制，当计算机内存中的一个对象不再需要被使用时，就会自动的让出这块内存。在早期的C/C++编程语言中，程序员需要自己手动申请和释放内存，而因在编程的过程中往往会经常忘记释放那些不再使用的内存，进而造成内存泄漏。垃圾回收机制可以大大减轻程序员的负担，减少程序员犯错的机会。垃圾回收机制最早起源于LISP语言，目前的大多数高级语言都支持内存回收机制，比如：PHP、Java、C#、Erlang等等。 垃圾回收算法的原理： 推算出某个对象在未来的程序运行中将不再会被访问。 将这些对象占用的内存回收。 收集器实现 引用计数收集器最早期的垃圾回收实现方法，通过对数据存储的物理空间附加多一个计数器空间，当有其他数据与其相关时则加一，反之相关解除时减一，定期检查各储存对象的计数器，为零的话则认为已经被抛弃而将其所占物理空间回收。是最简单的实现，但存在无法回收循环引用的存储对象的缺陷。 跟踪收集器近现代的垃圾回收实现方法，通过定期对若干根储存对象开始遍历，对整个程序所拥有的储存空间查找与之相关的存储对象和没相关的存储对象进行标记，然后将没相关的存储对象所占物理空间回收。 回收算法主要的回收算法可以分为以下几类： 标记－清除先暂停整个程序的全部运行线程，让回收线程以单线程进行扫描标记，并进行直接清除回收，然后回收完成，恢复运行线程。会导致大量零碎的空闲空间碎片，导致大容量对象不容易获得连续的内存空间，而造成空间浪费。 标记－压缩和“标记－清除”相似，不同的是，回收期间同时会将保留的存储对象搬运汇集到连续的内存空间。从而集成空闲空间。 复制需要程序将所拥有的内存空间分成两个部分。程序运行所需的存储对象先存储在其中一个分区（定义为“分区0”）。同样暂停整个程序的全部运行线程后，进行标记后，回收期间将保留的存储对象搬运汇集到另一个分区（定义为“分区1”），完成回收，程序在本次回收后将接下来产生的存储对象会存储到“分区1”。在下一次回收时，两个分区的角色对调。 增量回收器需要程序将所拥有的内存空间分成若干分区。程序运行所需的存储对象会分布在这些分区中，每次只对其中一个分区进行回收操作，从而避免程序全部运行线程暂停来进行回收，允许部分线程在不影响回收行为而保持运行，并且降低回收时间，增加程序响应速度。 分代由于“复制”算法对于存活时间长，大容量的储存对象需要耗费更多的移动时间，和存在储存对象的存活时间的差异。需要程序将所拥有的内存空间分成若干分区，并标记为年轻代空间和年老代空间。程序运行所需的存储对象会先存放在年轻代分区，年轻代分区会较为频密进行较为激进垃圾回收行为，每次回收完成幸存的存储对象内的寿命计数器加一。当年轻代分区存储对象的寿命计数器达到一定阈值或存储对象的占用空间超过一定阈值时，则被移动到年老代空间，年老代空间会较少运行垃圾回收行为。一般情况下，还有永久代的空间，用于涉及程序整个运行生命周期的对象存储，例如运行代码、数据常量等，该空间通常不进行垃圾回收的操作。通过分代，存活在局限域，小容量，寿命短的存储对象会被快速回收；存活在全局域，大容量，寿命长的存储对象就较少被回收行为处理干扰。 实现上面是垃圾回收的基本算法，有些编程语言的垃圾回收机制会使用上面的算法然后再自己进行改造优化性能。比如Erlang就同时使用分代回收和标记清除的算法来实现垃圾回收机制。","categories":[{"name":"基本概念","slug":"基本概念","permalink":"https://lintingbin2009.github.io/categories/基本概念/"}],"tags":[{"name":"GC","slug":"GC","permalink":"https://lintingbin2009.github.io/tags/GC/"}]},{"title":"Erlang代码热更新","slug":"Erlang代码热更新","date":"2017-05-04T15:30:18.000Z","updated":"2017-05-05T13:23:01.626Z","comments":true,"path":"2017/05/04/Erlang代码热更新/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/04/Erlang代码热更新/","excerpt":"","text":"通过上一篇的文章Erlang动态代码载入小实验，我们可以了解到Erlang的热更机制，在Erlang里面会维护两个版本的代码。在新版本载入的时候如果有进程在老版本运行的话，运行那些内部调用的函数（只通过函数名调用的）代码将不会被更新，只有那些通过M:F格式调用的内部函数才能热更。举个例子：123456789%% 如果代码在loop上执行的话，有两种情况loop() -&gt; io:format(\"v1 ~n\"), %% 这条语句这种情况不能热更 loop().loop() -&gt; io:format(\"v1 ~n\"), %% 这条语句这种情况可以热更 ?MODULE:loop(). 在Erlang里面有分本地调用（local calls）和外部调用（external calls），本地调用的函数名是不需要被导出的。本地调用的格式是Fun(Args)，外部调用的格式是M:F(Args)。 Erlang运行时会保存一份代码的两个版本，所有本地调用的函数地址都会指向程序运行时最初的那个版本（如上面例子的情况一），而所有外部调用的函数地址都会指向最新的版本（如上面例子的情况二）。所以如果想要让代码能够热更新的话，需要使用外部调用的格式。 在我们项目中一般热更的流程是先：code:soft_purge(ModName)或者code:purge(ModName)然后再code:load_file(ModName)进行热更，针对这一热更流程我之前一直存在两个问题，最近仔细研究下才找到了答案，分别是以下这两个问题： 为什么load_file之前要先soft_purge或者purge一下呢？这个是load_file函数的问题，如果在load_file执行的时候，本身要热更的模块就有一个老的版本的代码存在的话，load_file就会返回一个not_purged的错误代码，导致新版本不能正常的载入。如果load_file执行自动删除最老版本的话，就不需要purge了（像在Erlang Shell里面执行c(ModName)一样）。当然如果一个模块从来都没有热更过的话（在系统里面只有一个版本），直接使用load_file是没有问题的，不过之后就要先purge再load_file了。 soft_purge和purge有什么不同吗？函数的功能上是有所不同的，但是在我们项目的使用中几乎是没有什么不同的。soft_purge和purge的函数的功能区别是如果清理的模块的老的版本中有进程在上面运行的话，purge就会杀掉进程，然后把老的版本给清理掉，soft_purge则会清理失败。热更的时候是先执行purge然后再loadfile，由于进程一般都是在当前的版本上面执行，这时候老的版本上面不会有进程在运行，所以执行purge和soft_purge是一样的，如果真的想要热更的时候把进程杀掉的话应该执行purge/soft_purge-&gt;loadfile-&gt;purge。 以上就是我对Erlang代码热更的总结～","categories":[{"name":"Erlang入门教程","slug":"Erlang入门教程","permalink":"https://lintingbin2009.github.io/categories/Erlang入门教程/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"Erlang动态代码载入小实验","slug":"Erlang动态代码载入小实验","date":"2017-05-01T15:19:04.000Z","updated":"2017-05-01T15:57:39.008Z","comments":true,"path":"2017/05/01/Erlang动态代码载入小实验/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/01/Erlang动态代码载入小实验/","excerpt":"","text":"下面的内容为《Erlang程序设计（第2版）》8.10节的内容，这个动态代码载入的小实验非常的简单生动，通过这个小实验能够充分理解Erlang代码的载入机制。 动态代码载入是内建于Erlang核心的最惊人特性之一。它的美妙之处在于你无需了解后台的运作就能顺利实现它。它的思路很简单：每当调用 someModule:someFunction(…)时，调用的总是最新版模块里的最新版函数，哪怕当代码在模块里运行时重新编译了该模块也是如此。如果在a循环调用b时重新编译了b，那么下一次a调用b时就会自动调用新版的 b 。如果有许多不同进程正在运行而它们都调用了b，那么当b被重新编译后，所有这些进程就都会调用新版的b 。为了了解它的工作原理，我们将编写两个小模块：a和b。12345%% b.erl-module(b).-export([x/0]).x() -&gt; 1. 1234567891011121314151617%% a.erl-module(a).-compile(export_all).start(Tag) -&gt; spawn(fun() -&gt; loop(Tag) end).loop(Tag) -&gt; sleep(), Val = b:x(), io:format(\"Vsn1 (~p) b:x() = ~p~n\", [Tag, Val]), loop(Tag).sleep() -&gt; receive after 3000 -&gt; true end. 现在可以编译a和b，然后启动两个a进程。 1&gt; c(a).{ok,a}2&gt; c(b).{ok,b}3&gt; a:start(one). Vsn1 (one) b:x() = 1Vsn1 (one) b:x() = 14&gt; a:start(two). Vsn1 (one) b:x() = 1Vsn1 (two) b:x() = 1 这些a进程休眠3秒钟后唤醒并调用b:x()，然后打印出结果。现在进入编辑器，把模块b改成下面这样：1234-module(b).-export([x/0]).x() -&gt; 2. 然后在shell里面重新编译b。这是现在所发生的： 5&gt; c(b).{ok,b}Vsn1 (one) b:x() = 2Vsn1 (two) b:x() = 2 两个原版的a仍然在运行，但现在它们调用了新版的b。所以在模块a里调用b:x()时，实际上是在调用“b的最新版”。我们可以随心所欲地多次修改并重新编译b，而所有调用它的模块无需特别处理就会自动调用新版的b。现在已经重新编译了b，那么如果我们修改并重新编译a会发生什么？来做个试验，把a改成下面这样：12345678910111213141516-module(a).-compile(export_all).start(Tag) -&gt; spawn(fun() -&gt; loop(Tag) end).loop(Tag) -&gt; sleep(), Val = b:x(), io:format(\"Vsn2 (~p) b:x() = ~p~n\", [Tag, Val]), loop(Tag).sleep() -&gt; receive after 3000 -&gt; true end. 现在编译并启动a。 6&gt; c(a).{ok,a}Vsn1 (two) b:x() = 2Vsn1 (one) b:x() = 2Vsn1 (two) b:x() = 27&gt; a:start(three). Vsn1 (two) b:x() = 2Vsn1 (one) b:x() = 2Vsn2 (three) b:x() = 2Vsn1 (two) b:x() = 2 有趣的事情发生了。启动新版的a后，我们看到了新版正在运行。但是，那些运行最初版a的现有进程仍然在正常地运行旧版的a。现在可以试着再次修改b。1234-module(b).-export([x/0]).x() -&gt; 3. 我们将在shell里重新编译b，观察会发生什么。 8&gt; c(b).{ok,b}Vsn1 (one) b:x() = 3Vsn2 (three) b:x() = 3Vsn1 (two) b:x() = 3 现在新旧版本的a都调用了b的最新版。最后，再次修改a（这是第三次修改a了）。12345678910111213141516-module(a).-compile(export_all).start(Tag) -&gt; spawn(fun() -&gt; loop(Tag) end).loop(Tag) -&gt; sleep(), Val = b:x(), io:format(\"Vsn3 (~p) b:x() = ~p~n\", [Tag, Val]), loop(Tag).sleep() -&gt; receive after 3000 -&gt; true end. 现在，当我们重新编译a并启动一个新版的a时，就会看到以下输出： 9&gt; c(a).{ok,a}Vsn2 (three) b:x() = 3Vsn2 (three) b:x() = 3Vsn2 (three) b:x() = 3Vsn2 (three) b:x() = 310&gt; a:start(four). Vsn2 (three) b:x() = 3Vsn3 (four) b:x() = 3Vsn2 (three) b:x() = 3Vsn3 (four) b:x() = 3Vsn2 (three) b:x() = 3 这段输出里的字符串是由两个最新版本的a（第2版和第3版）生成的，而那些运行第1版a代码的进程已经消失了。在任一时刻，Erlang允许一个模块的两个版本同时运行：当前版和旧版。重新编译某个模块时，任何运行旧版代码的进程都会被终止，当前版成为旧版，新编译的版本则成为当前版。可以把这想象成一个带有两个版本代码的移位寄存器。当添加新代码时，最老的版本就被清除了。一些进程可以运行旧版代码，与此同时，另一些则可以运行新版代码。","categories":[{"name":"Erlang入门教程","slug":"Erlang入门教程","permalink":"https://lintingbin2009.github.io/categories/Erlang入门教程/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"Erlang中catch和try...catch的区别","slug":"Erlang中catch和try...catch的区别","date":"2017-05-01T08:06:51.000Z","updated":"2017-05-01T08:39:07.716Z","comments":true,"path":"2017/05/01/Erlang中catch和try...catch的区别/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/01/Erlang中catch和try...catch的区别/","excerpt":"","text":"在Erlang的错误处理中，catch并不是try…catch的缩写，try…catch和catch是不同的。下面我将通过一个例子来区别出他们的不同，为以后的使用做一个参考。123456789101112131415161718192021222324%% exception_test.erl 代码文件-module(exception_test).-compile(export_all).generate_exception(1) -&gt; a;generate_exception(2) -&gt; throw(a);generate_exception(3) -&gt; error(a);generate_exception(4) -&gt; exit(a);generate_exception(5) -&gt; &#123;'EXIT', a&#125;.test_use_catch() -&gt; [&#123;I, catch generate_exception(I)&#125; || I &lt;- lists:seq(1, 5)].test_user_try_catch() -&gt; [begin try generate_exception(I) of NormalRes -&gt; &#123;I, normal, NormalRes&#125; catch ErrorType : Error -&gt; &#123;I, exception, ErrorType, Error&#125; end end || I &lt;- lists:seq(1, 5)]. 12345678910111213141516%% 执行exception_test:test_use_catch().函数的返回结果[&#123;1,a&#125;, &#123;2,a&#125;, &#123;3, &#123;'EXIT',&#123;a,[&#123;exception_test,generate_exception,1, [&#123;file,\"exception_test.erl\"&#125;,&#123;line,7&#125;]&#125;, &#123;exception_test,'-test_use_catch/0-lc$^0/1-0-',1, [&#123;file,\"exception_test.erl\"&#125;,&#123;line,12&#125;]&#125;, &#123;exception_test,'-test_use_catch/0-lc$^0/1-0-',1, [&#123;file,\"exception_test.erl\"&#125;,&#123;line,12&#125;]&#125;, &#123;erl_eval,do_apply,6,[&#123;file,\"erl_eval.erl\"&#125;,&#123;line,674&#125;]&#125;, &#123;shell,exprs,7,[&#123;file,\"shell.erl\"&#125;,&#123;line,686&#125;]&#125;, &#123;shell,eval_exprs,7,[&#123;file,\"shell.erl\"&#125;,&#123;line,641&#125;]&#125;, &#123;shell,eval_loop,3,[&#123;file,\"shell.erl\"&#125;,&#123;line,626&#125;]&#125;]&#125;&#125;&#125;, &#123;4,&#123;'EXIT',a&#125;&#125;, &#123;5,&#123;'EXIT',a&#125;&#125;] 123456%% 执行exception_test:test_user_try_catch().函数的返回结果[&#123;1,normal,a&#125;, &#123;2,exception,throw,a&#125;, &#123;3,exception,error,a&#125;, &#123;4,exception,exit,a&#125;, &#123;5,normal,&#123;'EXIT',a&#125;&#125;] 通过上面的列子我们可以看到，如果使用标准的try…catch来处理错误的话，调用者是可以正确的识别出错误，然后对错误进行相应的处理的。 但是如果用的是catch来处理错误的话，情况是不能乐观的，使用catch处理错误，exception(1)和exception(2)返回的结果是一样的，exception(4)和exception(5)返回的结果是一样的。catch在处理throw的时候只是简单的把throw的内容给返回，在处理exit的时候会返回一个tuple是带’EXIT’和exit里面的内容的结果，在处理error的时候会把堆栈给打印出来（这点比较人性化）。 所以大家在使用catch的时候要注意catch的返回值，正常的情况下还是推荐使用try…catch来处理错误，不然很容易就会掉到坑里面的。","categories":[{"name":"Erlang入门教程","slug":"Erlang入门教程","permalink":"https://lintingbin2009.github.io/categories/Erlang入门教程/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"吴恩达机器学习课程练习实现","slug":"吴恩达机器学习课程练习实现","date":"2017-05-01T04:30:06.000Z","updated":"2017-05-01T04:52:15.583Z","comments":true,"path":"2017/05/01/吴恩达机器学习课程练习实现/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/01/吴恩达机器学习课程练习实现/","excerpt":"","text":"由于当前机器学习大火，让我对机器学习产生浓厚的兴趣，所以我就上网查了下机器学习的入门教程，大多数的人还是比较推荐吴恩达老师的机器学习课程的。所以我就在Coursera上面学习了吴恩达的机器学习课程，现在已经顺利的毕业了。在Coursera上面每学完一小节课程都会有相应的练习，系统会自动对你提交的练习进行打分，要达到指定的分数才能顺利通过，这点Coursera的体验还是做的比较好的，但是由于国内网络的原因，在Coursera上面看视频，如果不使用科学上网的话，有时候是看不了的。我做练习用的是Octave，用Octave提交代码的时候会报错，需要在练习中进行以下的代码替换: lib/submitWithConfiguration.m 文件66行 1responseBody = urlread(submissionUrl, &apos;post&apos;, params); 替换成：1[code, responseBody] = system(sprintf(&apos;echo jsonBody=%s | curl -k -X POST -d @- %s&apos;, body, submissionUrl)); 最后附上我的练习代码，有需要的可以自取，如果对你有帮助的话，记得给我星星哈～代码地址：https://github.com/lintingbin2009/machine-learning-ex","categories":[{"name":"代码","slug":"代码","permalink":"https://lintingbin2009.github.io/categories/代码/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://lintingbin2009.github.io/tags/机器学习/"}]},{"title":"剑指offer——C语言实现","slug":"剑指offer——C语言实现","date":"2017-05-01T04:09:54.000Z","updated":"2017-05-01T04:18:07.601Z","comments":true,"path":"2017/05/01/剑指offer——C语言实现/","link":"","permalink":"https://lintingbin2009.github.io/2017/05/01/剑指offer——C语言实现/","excerpt":"","text":"之前实习的时候为了能够比较顺利的找到一个实习，特意练习了下代码能力，期间看了挺多的算法书籍，然后把剑指offer书本上的那些练习大部分都自己用C语言实现了一遍。这些练习的代码都已经传到了Github上面了，地址是：https://github.com/lintingbin2009/C-language/tree/master/%E5%89%91%E6%8C%87offer有需要的可以自取，如果觉得对你有帮助的话，记得给我个星星哈～","categories":[{"name":"代码","slug":"代码","permalink":"https://lintingbin2009.github.io/categories/代码/"}],"tags":[{"name":"剑指offer","slug":"剑指offer","permalink":"https://lintingbin2009.github.io/tags/剑指offer/"},{"name":"C语言","slug":"C语言","permalink":"https://lintingbin2009.github.io/tags/C语言/"}]},{"title":"Erlang数据类型","slug":"Erlang数据类型","date":"2017-04-30T03:23:06.000Z","updated":"2017-04-30T11:11:25.854Z","comments":true,"path":"2017/04/30/Erlang数据类型/","link":"","permalink":"https://lintingbin2009.github.io/2017/04/30/Erlang数据类型/","excerpt":"","text":"Erlang提供的数据类型，包括以下几种： 基本类型 数字(Number)数字类型又包含整数(integers)和浮点数(floats)类型，其中整数是精确的而且是支持大数的，小数是满足IEEE754规则的64位浮点数。Erlang支持ASCII或者Unicode转换成整数值，同时支持整数不同进制的表示。（‘%’后的内容为注释） 1&gt; $a. %% ASCII表中的a是97972&gt; $哈.217043&gt; $\\n.104&gt; 2#100. %% 用100表示的二进制是445&gt; 4#100.166&gt; 16#100.256 原子(Atom)原子可以理解为一个不可变的常量，必须以小写字母开头，如果要以大写、下划线或者其他的特殊字符开头，必须加上单引号。原子在Erlang里面是存在一张表上面的，原子的个数有上限，大概是在一百万个左右。 test‘Myhome’‘_hero’ 位串和二进制(Bit Strings and Binaries)在大多数情况下，二进制型里的位数都会是8的整数倍，因此对应一个字节串。如果位数不是8的整数倍，就称这段数据为位串（bitstring）。所以当我们说位串时，是在强调数据里的位数不是8的整数倍。位语法是一种表示法，用于从二进制数据里提取或加入单独的位或者位串。当你编写底层代码，以位为单位打包和解包二进制数据时，就会发现位语法是极其有用的。 1&gt; &lt;&gt;. %%二进制型的元素如果大于8位的会自动截断，257截断成1&lt;&gt;2&gt; &lt;&gt;. %%二进制型位数如果不是8的整数倍就会产生位串，这边多了1位1&lt;&gt;3&gt; &lt;&gt;.&lt;&gt; 引用(Reference)可以通过make_ref/0函数来创建一个引用，引用在Erlang程序运行时调用make_ref函数产生的是全局唯一的。比如timer模块在创建一个定时任务的时候通常会返回一个引用，可以通过这个引用来取消定时任务。 函数(Fun)函数在Erlang里面也算是一种数据类型，通过给变量绑定函数，可以通过变量名来执行函数。 1&gt; Fun = fun(X) -&gt; X * X end.#Fun2&gt; Fun(9).81 端口标识符(Port Identifier)端口用于与外界通信，由通过函数open_port/2来创建。消息可以通过端口进行收发，但是这些消息必须遵守所谓“端口协议”(port protocol)的规则。 进程标识符(Pid)当创建一个进程的时候会产生一个进程标识符，可以通过这个进程标识符和进程进行通讯。 1&gt; Process1 = spawn(fun() -&gt; receive X -&gt; io:format(“recv ~p, bye~n”, [X]) end end). %% 创建一个进程等待接收消息2&gt; Process1 ! my_test. %% 给进程发消息recv my_test, byemy_test 复合类型为了方便定义以下的这些复合类型，我把上述的所有基本类型都称为Term。 元组(Tuple)元组类似于C语言里面的结构体(Struct)，是由固定数量的元素组成的复合数据类型，可以定义成如下结构： {Term1, Term2, …, TermN} 可以通过模式匹配或者element/2函数来提取元组里面元素的值，通过setelement/3来设置元组里面元素的值，size可以取元组里面元素的个数。 1&gt; P = {adam,24,{july,29}}.{adam,24,{july,29}}2&gt; element(1,P).adam3&gt; element(3,P).{july,29}4&gt; P2 = setelement(2,P,25).{adam,25,{july,29}}5&gt; size(P).36&gt; {adam, Old, {Month, Day}} = P.{adam,24,{july,29}}7&gt; Old.24 映射组(Map)映射组是一个由多个Key-Vaule结构组成的符合数据类型，可以定义为如下结构： #{Key1=&gt;Value1, Key2=&gt;Value2, …, KeyN=&gt;ValueN}其中Key、Value都是Term 可以通过maps模块提供的一些函数对映射组进行操作 1&gt; M1 = #{name=&gt;adam,age=&gt;24,date=&gt;{july,29}}.#{age =&gt; 24,date =&gt; {july,29},name =&gt; adam}2&gt; maps:get(name,M1).adam3&gt; maps:get(date,M1).{july,29}4&gt; M2 = maps:update(age,25,M1).#{age =&gt; 25,date =&gt; {july,29},name =&gt; adam}5&gt; map_size(M).36&gt; map_size(#{}).0 列表(List)列表类似于其他语言里面的数组，是由可变数量的元素组成的复合数据结构，可以定义成如下结构： [Term1, Term2, …, TermN] 在Erlang里面，列表由一个头和一个尾组成，空列表也是一个列表。所以列表也可以有一个递归的定义 List = [Term| List] | [][] 是一个列表, 因此[c|[]] 是一个列表, 因此[b|[c|[]]] 是一个列表, 因此[a|[b|[c|[]]]] 是一个列表, 或者简写为 [a,b,c] lists模块可以提供大量函数对列表进行操作： 1&gt; L = [3,3,4,2,1,2,34].[3,3,4,2,1,2,34]2&gt; length(L).73&gt; lists:sort(L).[1,2,2,3,3,4,34]4&gt; lists:reverse(L).[34,2,1,2,4,3,3] 其他类型(不算数据类型) 字符串(String)字符串用一对双引号括起来，但不算是Erlang中的数据类型。字符串仅仅是列表的一个缩写，比如：字符串”hello”是列表[$h,$e,$l,$l,$o]的一个缩写。两个相邻的字符串在编译的时候连接成一个字符串，不会造成任何运行时开销。 1&gt; “hello” “ “ “world”.“hello world” 记录(Record)记录其实就是元组的另一种形式。通过使用记录，可以给元组里的各个元素关联一个名称。对记录的处理是在编译的时候完成的，在运行时是不会有记录的，可以把记录理解成是元组的一种语法糖。 12345-module(person).-export([new/2]).-record(person, &#123;name, age&#125;).new(Name, Age) -&gt; #person&#123;name=Name, age=Age&#125;. 1&gt; person:new(ernie, 44).{person,ernie,44} 布尔类型(Boolean)在Erlang中没有Boolean类型。而是用原子true和false来表示布尔值。 1&gt; 2 =&lt; 3.true2&gt; true or false.true 类型转换Erlang提供了一些内置的类型转换函数，可以方便地进行类型转换，下面是一些类型转换的例子： 1&gt; atom_to_list(hello).“hello”2&gt; list_to_atom(“hello”).hello3&gt; binary_to_list(&lt;&lt;”hello”&gt;&gt;).“hello”4&gt; binary_to_list(&lt;&gt;).“hello”5&gt; list_to_binary(“hello”).&lt;&gt;6&gt; float_to_list(7.0).“7.00000000000000000000e+00”7&gt; list_to_float(“7.000e+00”).7.08&gt; integer_to_list(77).“77”9&gt; list_to_integer(“77”).7710&gt; tuple_to_list({a,b,c}).[a,b,c]11&gt; list_to_tuple([a,b,c]).{a,b,c}12&gt; term_to_binary({a,b,c}).&lt;&gt;13&gt; binary_to_term(&lt;&gt;).{a,b,c}14&gt; binary_to_integer(&lt;&lt;”77”&gt;&gt;).7715&gt; integer_to_binary(77).&lt;&lt;”77”&gt;&gt;16&gt; float_to_binary(7.0).&lt;&lt;”7.00000000000000000000e+00”&gt;&gt;17&gt; binary_to_float(&lt;&lt;”7.000e+00&gt;&gt;”).7.0","categories":[{"name":"Erlang入门教程","slug":"Erlang入门教程","permalink":"https://lintingbin2009.github.io/categories/Erlang入门教程/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"为什么使用Erlang?","slug":"为什么使用Erlang","date":"2017-04-29T14:00:09.000Z","updated":"2017-04-29T15:23:16.882Z","comments":true,"path":"2017/04/29/为什么使用Erlang/","link":"","permalink":"https://lintingbin2009.github.io/2017/04/29/为什么使用Erlang/","excerpt":"","text":"主要特性如果问我觉得Erlang最重要的特性是什么的话，我觉得应该是并发。 并发能够带来的好处是不言而喻的，比如： 性能现在的计算机由于主频的限制，都在往多核的方式发展，有些比较高端的机器甚至有几十个核心。如果编写的程序都是顺序运行的话将会严重浪费多核计算机的计算能力。Erlang本身是面向并发编程的，如果把之前在单核机器上面跑的Erlang程序放到多核机器上面跑的话，性能将会极大的提高。 扩展性如果在一台机器上面运行Erlang程序还不能满足性能的要求的话，可以简单的升级机器的CPU核心个数，甚至可以经过简单的改造把不同的进程分配到不同的机器上面运行，通过水平扩展方式来满足高并发的业务需求。 容错性Erlang内部实现的进程是相互独立的，一个进程的崩溃并不会影响到另外一个进程的运行，同时Erlang内部还OTP框架来保证系统的容错性。 清晰性Erlang世界观和现实的世界是一样的，在大多数的编程语言里面事情都是顺序发生的，但是在Erlang的世界里面所有的事件都是并发的，在编写程序的时候能够比较清晰的把现实世界事件的并行发生的的特性映射到Erlang的并发编程上面。 简介快速介绍下Erlang比较与众不认同的特性： Erlang Shell在编写Erlang程序的过程中会有很多时间花费在Erlang Shell里面，Erlang Shell类似于Linux的Bash，开发者能在Erlang Shell里面运行表达式，通过这种交互方式，开发者能够在Erlang Shell里面调试正在运行的Erlang程序（包括远程的Erlang程序）。 = 操作符在一般的编程语言里面，=表示赋值操作，一个变量能够被多次赋值。但是在Erlang里面变量是不可变的，一旦通过=绑定之后，该变量的值就不能发生改变了，重复绑定会导致异常。 变量和原子所有Erlang的变量都是以大写字母开头的，比如：One、This和My_baby这些都是变量。以小写字母开头的则是符号常量（被称为原子：atom），比如：person、one和hello_world。 进程Erlang的进程是Erlang虚拟机内部自己实现的进程，非常轻量级，刚开始创建的时候每个进程的大小也就2KB左右，1GB的内存就可以创建50万个进程。同时进程间没有共享内存，进程间的通信通过消息转发实现。 总结Erlang的特性决定了它是一门比较另类的语言，相信第一次见到它的人会觉得很吃惊，世界上居然会有这样的一门语言。但正是由于这些看似奇怪的特性，让Erlang能够在当今多核的时代充分的发挥它的能力。","categories":[{"name":"Erlang入门教程","slug":"Erlang入门教程","permalink":"https://lintingbin2009.github.io/categories/Erlang入门教程/"}],"tags":[{"name":"Erlang","slug":"Erlang","permalink":"https://lintingbin2009.github.io/tags/Erlang/"}]},{"title":"使用HEXO在Github上搭建个人博客","slug":"使用HEXO在github上搭建个人博客","date":"2017-04-29T07:40:51.000Z","updated":"2017-09-03T05:47:51.546Z","comments":true,"path":"2017/04/29/使用HEXO在github上搭建个人博客/","link":"","permalink":"https://lintingbin2009.github.io/2017/04/29/使用HEXO在github上搭建个人博客/","excerpt":"","text":"在平时的工作中经常会遇到一些问题，在解决问题的时候如果能够及时记录下来是最好不过的，所以一直想维护一个自己的博客。虽然国内有各种技术博客（比如：CSDN，博客园）之类的第三方博客平台，但是作为一个程序员，不搭建一个自己的博客感觉不够酷。所以我就选择使用HEXO在Github上面搭建自己的个人博客。 下面的安装教程都是在Window x64的环境下进行的 安装步骤 申请Github账户 由于博客是要搭建在Github上面的，所有必须要有一个Github账号来上传代码，这样才能最终显示自己的博客内容。在建立完Github账号后，需要创建一个Repositories，这个Repositories的名字的格式是:your_user_name.github.io这样的。 安装Git软件 有了Github账号后还需要有软件能把本地的代码上传到Github上面，所就安装Git软件，安装Git也非常简单，直接下一步就行了。 安装NodeJs 由于Hexo是基于NodeJs的框架，所以使用Hexo前要先安装NodeJs，安装NodeJs也非常简单，只需要下载软件，点下一步就行了。现在新的版本的NodeJs，会同时安装npm（Node包管理软件），所以安装起来非常简单。 安装Hexo 把上面的软件都安装好了之后就可以开始安装Hexo了，打开window的终端，在终端中输入下面的命令开始安装Hexo 1npm install -g hexo 使用步骤 初始化 创建一个文件夹，如：MyBlog之类，然后进到MyBlog文件夹下执行以下初始化命令 1hexo init 到了这一步之后，Hexo算初始化完成，可以正常的使用了。 生成静态页面 继续在MyBlog目录下执行如下命令，生成静态页面 1hexo generate // 简写 hexo g 本地启动 启动本地服务，进行文章预览调试，命令： 1hexo server // 动态启动，有修改发生会自动检测，简写 hexo s 然后在浏览器输入 http://localhost:4000 就可以看到博客的页面，当然也在服务器启动的时候加上-p来指定自己想要的端口 部署步骤 安装 hexo-deployer-git 1npm install hexo-deployer-git --save 配置部署环境 在MyBlog的目录下会有一个_config.yml的文件，该文件为Hexo项目的配置文件，打开该文件然后把deploy部分改成下列格式 1234deploy: type: git repository: https://github.com/lintingbin2009/lintingbin2009.github.io.git // lintingbin2009替换成你自己的名字 branch: master 开始部署 1hexo deploy 部署完成之后就可以使用your_username.github.io来访问你的个人博客了, 之后的部署命令应该是 123hexo cleanhexo generatehexo deploy 总结总的来说用Hexo在Github上搭建个人博客还是比较简单的，当然这边只是涉及到最简单的搭建，还没有涉及到主题的更换、评论系统，统计系统。更多关于Hexo的使用文档可以浏览Hexo的中文官网，里面有详细的使用教程和很多可选的精美主题。","categories":[{"name":"教程","slug":"教程","permalink":"https://lintingbin2009.github.io/categories/教程/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://lintingbin2009.github.io/tags/Hexo/"},{"name":"Github","slug":"Github","permalink":"https://lintingbin2009.github.io/tags/Github/"}]}]}